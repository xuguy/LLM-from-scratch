{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuguy\\AppData\\Local\\Temp\\ipykernel_30000\\3572444826.py:5: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'cupy'\n"
     ]
    }
   ],
   "source": [
    "# ======== a runnable full training procedure =========\n",
    "# resnet18 + adam ,test acc ~ 99.1%\n",
    "import sys\n",
    "sys.path.append(r'/kaggle/input/dezero')\n",
    "from imp import reload\n",
    "import os, dezero\n",
    "\n",
    "from dezero import Variable\n",
    "import dezero.functions as F\n",
    "reload(F)\n",
    "import numpy as np\n",
    "\n",
    "from dezero import optimizers\n",
    "reload(optimizers)\n",
    "from dezero import DataLoader\n",
    "# from dezero.models import MLP\n",
    "from dezero import models\n",
    "from dezero.models import ResNet18, MLP, C5L3\n",
    "from dezero.datasets import Dataset\n",
    "\n",
    "# we can use torch's data loader\n",
    "import torch\n",
    "import torchvision.datasets as tv_datasets\n",
    "import torchvision.transforms as tv_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "kaggle = \"/kaggle/input/cifar-10-dlhw1-2/data\"\n",
    "local = \"../data\"\n",
    "\n",
    "# switch between test and kaggle mode\n",
    "run_on_local = 1\n",
    "\n",
    "if run_on_local:\n",
    "    data_path = local\n",
    "    sys.path.append('./code')\n",
    "    \n",
    "else:\n",
    "    data_path = kaggle\n",
    "    sys.path.append('/kaggle/input')\n",
    "\n",
    "# define data transformation method：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1, 28, 28), (10000,)\n",
      "(60000, 1, 28, 28), (60000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuguy\\AppData\\Local\\Temp\\ipykernel_30000\\2927851848.py:15: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  data = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "# ======= prepare data ========\n",
    "data_path = local\n",
    "batch_size = 64\n",
    "num_workers = 0\n",
    "dataset1 = 'CIFAR10'\n",
    "\n",
    "# load with pickle\n",
    "# we download the mnist dataset and store it in .pkl\n",
    "import pickle\n",
    "\n",
    "# change the following lines to switch local/kaggle\n",
    "# filepath = r'./dezero/MNISTdataset/mnist.pkl'\n",
    "filepath = r'/kaggle/input/dezero/dezero/MNISTdataset/mnist.pkl'\n",
    "with open(filepath, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# setup hyper-params\n",
    "\n",
    "\n",
    "print_every = 1\n",
    "hidden_size = 1000\n",
    "\n",
    "max_epoch = 15\n",
    "batch_size = 64\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "# we only use tv_transform to transform the ndarray data\n",
    "g = tv_transforms.Compose([\n",
    "                tv_transforms.RandomRotation(15),  \n",
    "                tv_transforms.RandomHorizontalFlip(),\n",
    "                tv_transforms.RandomAffine(0, translate=(0.1, 0.1)),  \n",
    "                # tv_transforms.RandomResizedCrop(28, scale=(0.9, 1.1)), \n",
    "                # tv_transforms.ToTensor(),  \n",
    "                tv_transforms.Normalize((0.1307,), (0.3081,))])  \n",
    "\n",
    "def f(x):\n",
    "    return g(torch.tensor(x, dtype=torch.float32))\n",
    "\n",
    "# def f(x):\n",
    "#     # x = x.flatten()\n",
    "#     x = x.astype(np.float32)\n",
    "#     x /= 255.0\n",
    "#     return x\n",
    "\n",
    "test_set = Dataset()\n",
    "test_set.transform = f\n",
    "test_set.data= data['test_img'].reshape(-1, 1, 28, 28)\n",
    "test_set.label = data['test_label']\n",
    "print(f'{test_set.data.shape}, {test_set.label.shape}')\n",
    "\n",
    "\n",
    "train_set = Dataset()\n",
    "train_set.transform = f\n",
    "train_set.data= data['train_img'].reshape(-1, 1, 28, 28)\n",
    "train_set.label = data['train_label']\n",
    "print(f'{train_set.data.shape}, {train_set.label.shape}')\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "N = len(train_set)\n",
    "# model = MLP((1000,10))\n",
    "# model = ResNet18(pretrained=False)\n",
    "model = C5L3()\n",
    "# model = MLP((1000, 10), activation= F.leaky_relu)\n",
    "# Adam works\n",
    "optimizer = optimizers.Adam().setup(model)\n",
    "if dezero.cuda.gpu_enable:\n",
    "    train_loader.to_gpu()\n",
    "    test_loader.to_gpu()\n",
    "    model.to_gpu()\n",
    "\n",
    "\n",
    "# try to load weights (check if path exists)\n",
    "# if os.path.exists('my_mlp.npz'):\n",
    "#     model.load_weights('my_mlp.npz')\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "\n",
    "    for x, t in train_loader:\n",
    "        y = model(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        acc = F.accuracy(y, t)\n",
    "        optimizer.update()\n",
    "        sum_loss += float(loss.data)*len(t)\n",
    "        sum_acc += float(acc.data) * len(t)\n",
    "\n",
    "\n",
    "    # print training info\n",
    "    avg_loss = sum_loss / len(train_set)\n",
    "    avg_acc = sum_acc / len(train_set)\n",
    "    # if epoch % print_every == print_every-1 :\n",
    "    print(f'epoch: {epoch+1}, train_avg_loss: {avg_loss:.4f}, train_avg_acc: {avg_acc:.4f}')\n",
    "\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "    # print eval info\n",
    "    with dezero.no_grad():\n",
    "        for x, t in test_loader:\n",
    "            y = model(x)\n",
    "            # loss = F.softmax_cross_entropy(y, t)\n",
    "            acc = F.accuracy(y, t)\n",
    "            # sum_loss += float(loss.data) * len(t)\n",
    "            sum_acc += float(acc.data) * len(t)\n",
    "\n",
    "    \n",
    "    # print eval(test) info\n",
    "    # avg_loss = sum_loss / len(test_set)\n",
    "    avg_acc = sum_acc / len(test_set)\n",
    "    # if epoch % print_every == print_every-1 :\n",
    "    # print(f'test_avg_loss: {avg_loss:.4f}, test_avg_acc: {avg_acc:.4f}')\n",
    "    print(f'test_avg_acc: {avg_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([[ 1.77515229 -0.7487996   0.75166254 -0.04596518  0.34729091 -1.05023357\n",
       "            1.4510835   1.56595645 -2.77450248 -0.7332514 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # part 2, try to repeat C5L3 using dezero framework.abs\n",
    "# reload(dezero.models)\n",
    "# from dezero.models import C5L3\n",
    "# model = C5L3()\n",
    "# x = train_set.data[1].reshape(1,1,28,28)\n",
    "# model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize image after transform\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # remove batch dim to get an array of shape (28, 28)\n",
    "# img_arr = data['train_img'][1].reshape(-1,28,28)\n",
    "\n",
    "# img_arr = f(torch.tensor(img_arr, dtype = torch.float32))\n",
    "# image = image_array.squeeze()\n",
    "\n",
    "# # 展示图像\n",
    "# plt.imshow(img_arr.squeeze(), cmap='gray')  # gray projection\n",
    "# plt.axis('off')  # turn off axis\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-HW-Py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
