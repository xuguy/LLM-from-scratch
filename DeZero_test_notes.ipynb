{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(0.8473695850105871)\n",
      "variable(0.2514286285183606)\n",
      "variable(0.24759485466749864)\n",
      "variable(0.2378612044705481)\n",
      "variable(0.21222231333102917)\n",
      "variable(0.16742181117834146)\n",
      "variable(0.0968193261999265)\n",
      "variable(0.07849528290602333)\n",
      "variable(0.07749729552991155)\n",
      "variable(0.07722132399559314)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x199b82dd8a0>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGdCAYAAADuR1K7AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAATlFJREFUeJzt3QlYVGXfBvAbZlgEWURkUxQVxR1cEZfKMi3NpbK0LJdSy/asLHtLLSvLylbTL3tLK8ul3FIjd83EDUTFxAUXQFlVdllnvut5gHmlAFEZzsw59++6Tp4ZDsOfozE3z2pjNBqNICIiIlIJW6ULICIiIqpNDDdERESkKgw3REREpCoMN0RERKQqDDdERESkKgw3REREpCoMN0RERKQqDDdERESkKnpokMFgwIULF+Di4gIbGxulyyEiIqIaEOsOZ2dnw8/PD7a2VbfPaDLciGDj7++vdBlERER0AxISEtCkSZMqP67JcCNabMpvjqurq9LlEBERUQ1kZWXJxony9/GqaDLclHdFiWDDcENERGRdrjWkhAOKiYiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVRhuiIiISFUYboiIiEhVGG6IiIhIVTS5cSbRzcovKsGJlGxczCnEpdyyI68QBqMR7vXs0cDJDu5OdmjgZI82vq5wq2endMlERJrBcENUA6lZ+dhz5hKizl3GwfjLOHohC8UGY40+V2xe29rLBV0DGqBbswbo2aIh/Nzrmb1mIiKtYrghqkJ2fhF+j0nG6oPnEXH6Ioz/yDINne3h6+4oW2c8nEVrjT1sbWyQeaUIGXmFyLhShJSsfCRevoLjKdny+GlvvPzcvq088VCPpujf1hv2evYOExFZTbjZuXMnPvzwQ0RGRiIpKQmrVq3C8OHDq7x++/bt6Nev37+eF5/r4+Njejxv3jz5usnJyQgODsYXX3yBHj16mO37IG3Zd+YSFkecxea/U1BQbDA936GxK7o180Dnpu7o0rQBmjSoBxvRLHMNadkFiDx3GZHnLmH/2cuITsjAnyfT5SEC0ohuTTA2LICtOURE1hBucnNzZfh47LHHcN9999X4844fPw5XV1fTYy8vL9P5smXLMGXKFCxYsAChoaH49NNPMXDgQPk5V19HdD2MRiN2x13EZ1tOynBTrmUjZ9zXpQmGBvvB38Pphl67kYsD7urgIw8h4VIelu1PwPIDCUjNLsD/7TiNRX+dxaRbWuDJW1vC2YENqkREN8PGKH6q1wHxG25NW24uX74Md3f3Sq8RgaZ79+748ssv5WODwQB/f388++yzeO2112pUS1ZWFtzc3JCZmVkhRJE27TiRhs82n0BUfIZ8bK+zxf1dm2B0aFO093OtUevMjSguMWBrbCq+2XXGFKi8XBzw8sAgjOjSBLa25vm6RETWqqbv3xb5K2JISAgKCgrQoUMHzJw5E71795bPFxYWyi6uadOmma61tbVF//79ERERUeXridcSx9U3h0i0oLz121FsPpYqHzvobeU4mCdubQFfN/N3Eel1thjQ3gd3tvPGH0dT8N6GY4i/lIepvxzG9xFn8cmDIWjl7WL2OoiI1MaiRjL6+vrK7qZff/1VHqJF5rbbbkNUVJT8eHp6OkpKSuDt7V3h88RjMf6mKrNnz5ZJr/wQr0vaVVBcgnnbTuHOT3bIYGOns8HjfZrjz1f7YebQ9nUSbK4mWoZEl9WmKbfg9UFt4OKgR8z5LAz5cpfsuqqjxlUiItWwqJaboKAgeZTr1asX4uLi8Mknn+CHH3644dcVLT1inM7VLTcMONq09/RFTFt1BKfTcuXjsBYNMWt4ewR6Kd9C4qDXYdItLTG8c2O8tPyQHHAsWnH2xF3ErOEdOBaHiKiGLP6npZgFtWvXLnnu6ekJnU6HlJSUCteIx1fPpvonBwcHeZB2FZUY8OnmE/hqe5yc0u1Z3wFv3tNWDhQ215iaG+Xl4ojF43tg/o44fLzxOFYePI/oxAx8NboL2vhwjBgRkVV1S1UmOjpadlcJ9vb26Nq1K7Zs2WL6uBhQLB6HhYUpWCVZsviLeXhgQQTmbSsNNg92a4KtL9+KYSGNLS7YlBODiZ/uF4ilk8Lg4+ooW5pGzI9ARNxFpUsjItJ2y01OTg5OnTplenzmzBkZVjw8PNC0aVPZXXT+/Hl8//338uNiWnfz5s3Rvn175Ofn45tvvsHWrVuxceNG02uI7qWxY8eiW7duslVHfI6Ycj5+/HhzfitkpdZEn8d/VsUgp6AYLo56zL6vI+7p5Adr0aO5BzY83xeTf4zE3jOXMPa7ffjyoc5yIDIRESkQbg4cOFBhUb7ycS8inCxatEguzhcfX7pia/lsqJdeekkGHicnJ3Tq1AmbN2+u8BojR45EWloapk+fLgcRi5lV4eHh/xpkTNomplm/s/4YFu0+Kx+LbQ8+HRWCJg1ubK0aJYnVjxc/1gPP/nwQm/5OweQlUfjg/k4Y0bWJ0qUREWl7nRtLwnVu1C0zrwjP/BwlB+QKz93RCs/dHiinXlt7YHtt5RH8EpkoH78xuC0m9G2hdFlERHXGqte5IbpRp9NyMGHxAZxOz4WTvQ5zHwwxrQxs7UQ4m3N/J7nD+H93nZEtU2IXcjHDioiI/ofhhlRj18l0PLUkEln5xWjsXg8Lx3RDOz91tcyJgcaixUYEnLmbTuC9DbFy5pfYIoKIiEpZdzs9UZnfDl3A+EX7ZLAR42vWPNNbdcGmnJjh9eztgXisd3P5WKyFs/146SrLRETEcEMq8MOec3hu6UEUlRgxJNgPSyaGytYMNRMBR7TgiHV6ig1GPLUkCocSSvfGIiLSOoYbslpiLPyXW0/izdUxcv2aR3s2w2cjQ+RKv1oguqg+eiAYfQI9kVdYgvGL9ssxR0REWsdwQ1bJYDDKAbUfbTwhH4vZUG8Pa6+5nbTt9bZY8GhXdGjsiku5hRj33X45W4yISMsYbsgqW2zeXBMjZwwJ0+9phykDgix2tWFzq++gx3fjeqBJg3pyV/Epy6Nl+CMi0iqGG7K6YDNz7VEs2RsPkWVEt8xjfUoH1mpZIxcHLHikq2zJ2RKbKvelIiLSKoYbsqpg8/a6v7E44pwMNh+OCOYqvVfp0NgNs4a1l+diw82/TpUuYkhEpDUMN2Q1wea9Dcfw3V+l2ym8f19HBptKjOzeVG4MKnqlnvv5IJIyryhdEhFRnWO4Iavw4R/HsfDP0jE2793bUb6JU+XeHtYB7XxdcTG3EE8viUJhsUHpkoiI6hTDDVm8r3fG4avtpWNIRLfLw6EMNtVxtNPJ8TeujnpExWfILioiIi1huCGL9mtkotxiQHjt7jZ4NCxA6ZKsQtOGTnKwtfD1n6cRee6S0iUREdUZhhuyWNtiUzH118PyfEKf5njiFu6AfT0GtPfB/V2ayAUOX1p+CHmFxUqXRERUJxhuyCJFxV+WWwqUGIy4t3NjvD6orWbXsbkZ04e0g4+rI85ezMOccHZPEZE2MNyQxTmVmoPHFu3HlaIS3Nq6EeaM6KS5lYdri9g9XNw/YdHus9jN6eFEpAEMN2RRLuYUyN29M/KKEOzvjq9Gd4Gdjv9Mb8YtrRuZBmG/8sthZOdzewYiUje+a5DFKCguwRM/RCLh0hU09XDCt2O7wdlBr3RZqiC69cT2DOczruDd9ceULoeIyKwYbshiFul79ZfDOHDuMlwc9fh2XHc0rO+gdFmq2n+qfPbU0v0J2HP6otIlERGZDcMNWYTPt5zC6ugL0NnaYP7orgj0qq90SarTs0VDU/fU9DUxKCrh4n5EpE4MN6S4tYcu4JPNJ+T5rGEd0KeVp9IlqdbUgUFo4GSHEyk5WLy7dCsLIiK1YbghRR1OzMDLKw7J84l9m3P1YTNzd7KXiyEKn2w6geTMfKVLIiKqdQw3pJj0nAI5gFjsfXRHGy+8dndbpUvShAe6+qNzU3fkFpbg3Q0cXExE6sNwQ4oQ4z3Epo5Jmflo4emMT0aFyPE2ZH5izSDR/Sdu92+HLnDtGyJSHYYbUoSYjrz3zCU5i+frMWKTRzulS9KUDo3d8GjPZvJ8+tqj3DmciFSF4YYU2QxTrJYrfPxgMAK9XJQuSZOmDAiCZ317uSL0d3+dUbocIqJaw3BDdepIYiZeX3VEnj93eyAGtvdRuiRNb81QPs7py22ncDm3UOmSiIhqBcMN1ZnMvCJMXhKJgrIBxC/0b610SZp3X+fGaOvriuz8YhlwiIjUgOGG6mwF4pdWRCPxcunWCnNHhnAzTAsg/g6mlU0N/yHiHBIu5SldEhHRTWO4oTrx9c7T2HwsFfZ6W7kZpugSIcvZWLNvK08Ulhjw0cbjSpdDRHTTGG7I7PafvYQ5f5S+ac4Y0k7O1CHL8updpa03a6IvyHFRRETWjOGGzL5Q3zM/RaHEYMSwED883IMrEFsiETjv7dxYns/+/ZjsRiQislYMN2Q2ItC8uCwaKVkFciPM9+7tCBsbjrOxVFPubA17nS12x13EjhNpSpdDRGSZ4Wbnzp0YMmQI/Pz85Jva6tWrq71+5cqVuPPOO9GoUSO4uroiLCwMf/zxR4VrZs6cKV/r6qNNm9ImdbIsC3bE4c+T6ahnp8P80V3g7KBXuiSqhr+HE8b2Kl3Y7/3fY2U4JSKyRmYNN7m5uQgODsa8efNqHIZEuNmwYQMiIyPRr18/GY4OHjxY4br27dsjKSnJdOzatctM3wHdqKj4y5i7qXSn77eGtUcrby7UZw2e7hcIV0c9YpOzsf5IktLlEBHdELP+Kn333XfLo6Y+/fTTCo/fe+89rFmzBr/99hs6d+5sel6v18PHh4u/Waqs/CI89/NB+Zv/0GA/PNC1idIl0XXsGj6xbwt8vOkEPt9yEoM7+nLPLyKyOhY95sZgMCA7OxseHh4Vnj958qTs6mrRogVGjx6N+Pj4al+noKAAWVlZFQ4yDzEQ9fWVR+R6Nk0a1MM793bgOBsrM7Z3gJyqL7ZlYOsNEVkjiw43H330EXJycvDggw+angsNDcWiRYsQHh6O+fPn48yZM+jbt68MQVWZPXs23NzcTIe/v38dfQfasyIyEesOJ8nf9j9/qDM3xLRC4u/s8T7N5fkXW05y7A0RWR2LDTc//fQT3nrrLSxfvhxeXl6m50U31wMPPIBOnTph4MCBcnxORkaGvK4q06ZNQ2ZmpulISEioo+9CW+LScjBjzVHTzJsuTRsoXRLdoHG9A+TYm5OpOdjA1hsisjIWGW6WLl2KCRMmyMDSv3//aq91d3dH69atcepU1fviODg4yNlXVx9UuwqLDXh+6UFcKSpBr5YN8eStLZUuiW6y9WZC3xbyXIy9MbD1hoisiMWFm59//hnjx4+Xfw4ePPia14tuq7i4OPj6+tZJfVS5TzefQMz5LLg72WHugyEchKq21psYtt4QkfUwa7gRwSM6OloeghgfI87LBwCL7qIxY8ZU6IoSjz/++GM5tiY5OVkeoiup3Msvv4wdO3bg7Nmz2L17N+69917odDo89NBD5vxW6BrbK4g1bQSxUJ+Pm6PSJVGtjb1h6w0RWR+zhpsDBw7IKdzl07inTJkiz6dPny4fizVqrp7p9PXXX6O4uBhPP/20bIkpP55//nnTNYmJiTLIBAUFyYHGDRs2xJ49e+TCf1T3svOLMGV5NMT73n1dGmNQR7agqa31xsVRjxMpOfg9JlnpcoiIasTGqMFNZMRUcDFrSrQIcfzNzXllxSE5Q6qxez38/kJfzo5SaZfjp5tPoo2PC35/vi+n9hORxb9/W9yYG7Ie4TFJMtiI97pPRoYw2KjU+F7N4WSvk6sW7zyZrnQ5RETXxHBDNyQ1Ox/TVh6R50/c0hI9mldcaJHUw83JDg+V7eb+f2Vjq4iILBnDDd3gKsQxuJxXhLa+rnjxzlZKl0Rm9lif5tDb2sgdww8nZihdDhFRtRhu6LqtjDqPzcdSYKezwScjg+Gg1yldEpmZGFMl9gkT/m/HaaXLISKqFsMNXZfkzHzM/K10FeIX+rdGGx8OyNaKSbeWTgv/PSYJZ9NzlS6HiKhKDDd0Xd1Rr/56GNn5xQj2d8cTt5S+2ZE2iCB7W1AjOe3/m11svSEiy8VwQzW2bH8CdpxIg73eFh8/0Al6Hf/5aI0YPC6sOJCI9JwCpcshIqoU352oRhIv5+Gd9cfk+csDWiPQy0XpkkgBPVt4ILiJGwqKDfh+91mlyyEiqhTDDdWoO+q1X48gp6AY3Zo1MC3JT9ojFvB7omxT1MUR55BbUKx0SURE/8JwQzXqjtp1Kh2Odrb48IFgboqpcQPb+yCgoRMyrxThl8hEpcshIvoXhhuqVlLmFbxr6o4KQnNPZ6VLIoWJcDuuV4A8X7z7LDfUJCKLw3BD1XZHvbEqBtkFxQjxd8f43s2VLoksxIhu/qjvoMfp9FzsPJmmdDlERBUw3FCV1kRfwJbYVNjrbPHhiE7sjiITEWwe6NZEni/iwGIisjAMN1SptOwC02J9z90RiFbenB1FFY0NC5Cbpm4/noa4tBylyyEiMmG4oUrNXHsUGXlFaOfrapodQ3S1AE9n3B7kJc85LZyILAnDDf3LH0eTsf5IkuyGmjOiE+y4WB9VoXwclpg1lZVfpHQ5REQS37WoAvEG9ebqGHkutlfo0NhN6ZLIgvUObIhWXvWRW1giVy0mIrIEDDdUwQe/xyI1u0BO+X7ujlZKl0NWsKjfuN7/mxZewmnhRGQBGG7IZP/ZS1iyN16ev3dvRzja6ZQuiazAvZ0bw9VRj/hLedgWm6p0OUREDDdUqqC4BK/9eliej+zmj7CWDZUuiayEk70eD/VoKs85LZyILAHDDUlfbYtDXFouPOs74PVBbZUuh6zMIz2byWnhYpuOM+m5SpdDRBrHcEM4mZKNr7afkuczh7aDm5Od0iWRlfH3cEK/smnhP+09p3Q5RKRxDDcaJ/YFmrbyCIpKjLijjRcGd/RVuiSyUqNDS7umVkQmIr+oROlyiEjDGG40btmBBBw4dxnO9jrMGt5Bzn4huhG3BXnBz81RLv74e0yS0uUQkYYx3Gh8i4XZG0p3/J4yIAh+7vWULomsmFj0sXxg8Y97SmfdEREpgeFGw95d/zey8ovR3s8VY8OaKV0OqcDI7v7Q29og8txlHEvKUrocItIohhuN2nUyHaujL8gZLmJNGz23WKBa4OXqiAHtveX5T2VrJhER1TW+o2mQGOz5xuoj8nxMz2YI9ndXuiRSkdGhpa2Aqw6eR25BsdLlEJEGMdxo0FfbTuHsxTx4uTjgpYFBSpdDKhPWoqHcviOnoBhroi8oXQ4RaRDDjcacSs3B/B1x8nzGkPZwdeSaNlS7bG1tTNPCl+w9B6OR+00RUd1iuNEQ8SYjdvwWa9rcFtQIgzr6KF0SqdT9XZrAXm+LoxeyEJ2QoXQ5RKQxDDcasvbQBUScvggHvS3eHso1bch8GjjbmxaEXLY/QelyiEhjGG40Iiu/CLPWla5p80y/QDRt6KR0SaRyYlq48NuhCxxYTETqCTc7d+7EkCFD4OfnJ1sJVq9efc3P2b59O7p06QIHBwcEBgZi0aJF/7pm3rx5CAgIgKOjI0JDQ7Fv3z4zfQfqMXfjCaTnFMiBnpNubaF0OaQBoc09ENDQCbmFJVh/mCsWE5FKwk1ubi6Cg4NlGKmJM2fOYPDgwejXrx+io6PxwgsvYMKECfjjjz9M1yxbtgxTpkzBjBkzEBUVJV9/4MCBSE1NNeN3Yt1izmfi+4iz8vztYe3hoNcpXRJpgPiF5sGy1huxzQcRUV2xMdbRVAbxg27VqlUYPnx4lde8+uqrWL9+PWJiYkzPjRo1ChkZGQgPD5ePRUtN9+7d8eWXX8rHBoMB/v7+ePbZZ/Haa6/VqJasrCy4ubkhMzMTrq6uUPvGmPfN3y0Hdd7TyRdfPtxF6ZJIQ1Kz8hH2/laUGIzYPOUWBHq5KF0SEVmxmr5/W9SYm4iICPTv37/Cc6JVRjwvFBYWIjIyssI1tra28nH5NZUpKCiQN+TqQyvEb8wi2NR30OPNe9opXQ5pcMXifkFe8pwDi4morlhUuElOToa3d+nS7eXEYxFGrly5gvT0dJSUlFR6jfjcqsyePVsmvfJDtPRowaXcQnwQHivPX7yzNbxdHZUuiTQ8sHhl1HkUFhuULoeINMCiwo25TJs2TTZhlR8JCdr4DfLDP2KRkVeENj4u3BiTFNMvqBEauTjgYm4htsamKF0OEWmARYUbHx8fpKRU/OEnHot+tXr16sHT0xM6na7Sa8TnVkXMvBKvcfWhdocSMrC0rBvg7WEduDEmKUb82xvRtYk8Z9cUEdUFi3rHCwsLw5YtWyo8t2nTJvm8YG9vj65du1a4RgwoFo/Lr6HSQcTT18RADBW/t3Nj9GjuoXRJpHEPdivtmtpxIg1JmVeULoeIVM6s4SYnJ0dO6RZH+VRvcR4fH2/qLhozZozp+ieffBKnT5/G1KlTERsbi6+++grLly/Hiy++aLpGTANfuHAhFi9ejGPHjmHy5Mlyyvn48ePN+a1Y3SDiQ4mZcHHQY9qgNkqXQyTXVxIh22AEfjmQqHQ5RKRyenO++IEDB+SaNVcHE2Hs2LFycb6kpCRT0BGaN28up4KLMPPZZ5+hSZMm+Oabb+SMqXIjR45EWloapk+fLgcRh4SEyGni/xxkrFUZeYWYUzaI+IU7W8PLhYOIyTKM6u6PfWcuYXlkAp7uFyg32CQisup1biyJmte5+c+qI1iyNx5B3i5Y/1wfjrUhi3GlsATd392MnIJiLJ3UEz1bNFS6JCKyMla5zg3dnCOJmfhpX7xpJWIGG7Ik9ex1ciFJ4ddIdk0Rkfnw3U9Ng4jXlg4iHhbih1D+VkwW6P6yWVMbjiQhr5CbaRKReTDcqMSqg+dxMD4DzvY6vD6ordLlEFWqW7MGaFa2mWZ4TNULbxIR3QyGGxXIzi/C7N9LBxE/e0crrkRMFkvsMXd/l9LWm1+j2DVFRObBcKMCX2w9hfScAjnddnzvAKXLIaqWWHtJ2B13EeczuOYNEdU+hhsrdyo1B9/uOiPPpw9pBwe9TumSiKrl7+GEsBYN5fiwVWy9ISIzYLixYmIW/1u/HUWxwYg72niZdl8mspaBxb9GnZf/jomIahPDjRXb9HcK/jyZDnudLd68p53S5RDV2N0dfOBkr8OZ9FxExV9WuhwiUhmGGyuVX1SCWev/lucT+jZHgKez0iUR1Zizgx53dyhd8+aXyPNKl0NEKsNwY6W++fM0Ei5dgberg1zKnsjalO8Uvu7QBRnWiYhqC8ONFUrOzMe8bXHyXKxpI34LJrI2oc090Ni9HrILivHHUa55Q0S1h+HGCn0QHosrRSXo2qwBhgb7KV0O0Q0RG2fe36V0Wvjqg+yaIqLaw3BjZSLPXZarEdvYADOGtJOLohFZq+Fla97sPJmOtOwCpcshIpVguLGy/aPE1G/hga5N0KmJu9IlEd2UFo3qI9jfHSUGI9YdvqB0OUSkEgw3VuSXqEQcTsxEfQc9Xh4YpHQ5RLXivrLWG9EiSURUGxhurGj/qDnhx+X5s7cHwsuF+0eROtzTyRd6WxsZ3MWK20REN4vhxkp8ue3q/aOaK10OUa1pWN8Bt7ZuJM85sJiIagPDjRU4m55r2j/qP4Pawl7PvzZS58Di1dHn5dgyIqKbwXdJKzD792MoKjGibytP3NGW+0eR+tzZzluOJUu8fAUHznE7BiK6OQw3Fm53XDr+OJoCna2N3D+KU79JjRztdHK/KYEDi4noZjHcWDAxPfbt30r3jxod2hStvV2ULonIbO4t65paf5jbMRDRzWG4sWDL9icgNjkbro56vNi/tdLlEJlVzxYN4evmiKz8Ymw/nqp0OURkxRhuLFRWfhE+3lg69fuF/q3RwNle6ZKIzL4dw9CQ0u1EVkaxa4qIbhzDjYWat/UULuYWokUjZzwa1kzpcojqxH2dS3cK33Y8FRl5hUqXQ0RWiuHGUqd+/1U69fvNwe1gp+NfE2lDkI8L2vi4yNmBv8dwp3AiujF817Tgqd+3tG6Efm049Zu0uebNmmh2TRHRjWG4sTARcRf/N/V7cFulyyGqc0OCS8fd7D1zCUmZV5Quh4isEMONhU39fmd96dTvh3s0RStO/SYNauxeDz0CPGA0Ar8d4k7hRHT9GG4syK9RiTh6IQsujnq80L+V0uUQKaZ81tSaaIYbIrp+DDcWIregGB/+8b9dv8VmgkRaNbhj6U7hIuyfSs1WuhwisjIMNxZiwY44pGUXoFlDJ4ztFaB0OUSKEus6le8UztYbIrpeDDcW4HzGFXy987Q8n3Z3GzjodUqXRGRRXVNGMQCHiKiGGG4swJzwWBQUGxDa3AMD25duHkikdWKncCd7HeIv5eFgQobS5RCRFamTcDNv3jwEBATA0dERoaGh2LdvX5XX3nbbbXLn638egwcPNl0zbty4f338rrvugjWKTsiQv5mKzb7fGMxdv4nKOdnrMaCdtzxfy64pIrKkcLNs2TJMmTIFM2bMQFRUFIKDgzFw4ECkpla+Md7KlSuRlJRkOmJiYqDT6fDAAw9UuE6Emauv+/nnn2FtRFP7O+v+Ni0737GJm9IlEVmUYSGlC/qtO3wBxSUGpcshIith9nAzd+5cTJw4EePHj0e7du2wYMECODk54dtvv630eg8PD/j4+JiOTZs2yev/GW4cHBwqXNegQQNYm/CYZBw4dxmOdrZ4ZWCQ0uUQWZw+rTzh4WyP9JxC/BV3UelyiMhKmDXcFBYWIjIyEv379//fF7S1lY8jIiJq9Br//e9/MWrUKDg7O1d4fvv27fDy8kJQUBAmT56Mixer/sFXUFCArKysCofSCopL8H54rDyfdEtL+Lg5Kl0SkcUR+6qJaeECt2MgIosIN+np6SgpKYG3d2m/eTnxODn52pviibE5oltqwoQJ/+qS+v7777FlyxZ88MEH2LFjB+6++275tSoze/ZsuLm5mQ5/f38o7YeIczh3MQ+NXBzwxC0tlC6HyOJnTW08moL8osr/HycisprZUqLVpmPHjujRo0eF50VLztChQ+XHhg8fjnXr1mH//v2yNacy06ZNQ2ZmpulISEiAki7nFuLzLSfl+SsDguDsoFe0HiJL1rVpA/i5OSKnoBjbYisfq0dEVGfhxtPTUw4GTklJqfC8eCzGyVQnNzcXS5cuxeOPP37Nr9OiRQv5tU6dOlXpx8X4HFdX1wqHkj7bchJZ+cVo4+OC+7s2UbQWIktna2tj2kxzLfeaIiKlw429vT26du0qu4/KGQwG+TgsLKzaz12xYoUcK/PII49c8+skJibKMTe+vqV985bsdFoOftxzTp6Lqd9i928iql55uNkSm4rs/CKlyyEirXdLiWngCxcuxOLFi3Hs2DE5+Fe0yojZU8KYMWNkt1FlXVKiy6lhw4YVns/JycErr7yCPXv24OzZszIoDRs2DIGBgXKKuaX7IDwWxQYjbm/jJWeCENG1tfdzRYtGzigsNsixN0RE1TH7YI+RI0ciLS0N06dPl4OIQ0JCEB4ebhpkHB8fL2dQXe348ePYtWsXNm7c+K/XE91chw8flmEpIyMDfn5+GDBgAGbNmiW7nyzZ3tMX8cfRFNla8/qgNkqXQ2Q1xOKWQ4P98Onmk7Jrit25RFQdG6MGN20RU8HFrCkxuLiuxt8YDEbc+9VfOJSYidGhTfHuvR3r5OsSqYXo0r394x3yl4N9r9+BhvUt+5cZIlLu/duiZ0upyW+HL8hg42yvwwv9WytdDpHVadGoPjo0dkWJwYgNMddeSoKItIvhpg6ItTnmhB+X55NvaynXtiGi6ye6poTfOGuKiKrBcFMHFu0+i/MZV+Dr5ojH+3DBPqIbdU+n0nCz/+wlJGVeUbocIrJQDDdmdim3EPO2lq6/8/KAINSz1yldEpHV8nOvhx4BHhAjBdcdSlK6HCKyUAw3ZvbZ5hPILihGO19X3Nu5dIdjIrpxQ8q2Y+CCfkRUFYYbM8/uWLI3Xp6/MbitXGmViG7OoA4+csbUkfOZ8v8xIqJ/YripowX7egVywT6i2iCmgPcp+/9p3WF2TRHRvzHcmIkY8CgW7BONNdPu5oJ9RLXp6r2mNLhUFxFdA8ONGYgftu+uPybPR3b3RytvF6VLIlKVAe29Ya+3xanUHMQmZytdDhFZGIYbM1h/JAnRCRlwstfhRS7YR1TrXB3t0C+okTznmjdE9E8MN7WsoPh/C/ZNuqUFvFwdlS6JSNVdU2L1b3ZNEdHVGG5q2Y974hF/KU+uQjyxLxfsIzKXO9p4y9bRhEtX5NYmRETlGG5qUWZeEb7YelKeT7mzNZwdzL7pOpFmiQUx72znLc/XRrNrioj+h+GmFs3bfgoZeUVo7V0fD3RtonQ5RKo3pGw7hnWHL8gNNYmIBIabWiRWIfZxdcS0u9tCr+OtJTK3vq094eqoR2p2gVx+gYhI4DtwLRreuTG2v3IbbiubxUFE5uWg1+GuDj7ynLOmiKgcw00tc7TTwcaG2ywQ1ZWhwaV7tm04koSiEoPS5RCRBWC4ISKr1rOFBzzr2+NyXhH+OpWudDlEZAEYbojIqonxbYM6+spz7hRORALDDRFZvaFlC/ptOpqC/KISpcshIoUx3BCR1evStAH83ByRXVCM7cfTlC6HiBTGcENEVs/W1gb3XLUdAxFpG8MNEalqQb8tx1KQW1CsdDlEpCCGGyJShQ6NXdHc0xn5RQZsPpaidDlEpCCGGyJSBbG+1JBOpbOmuKAfkbYx3BCRagwpG3ez40Sa3MiWiLSJ4YaIVKOVtwva+LigqMSI8KNJSpdDRAphuCEiVbbe/HaI4YZIqxhuiEiVs6Z2x6UjLbtA6XKISAEMN0SkKk0bOiHY3x0GY+lmmkSkPQw3RKQ6nDVFpG0MN0SkOvd08oONDXDg3GWcz7iidDlEVMcYbohIdXzcHNEjwEOer2PrDZHm1Em4mTdvHgICAuDo6IjQ0FDs27evymsXLVokF+O6+hCfdzWj0Yjp06fD19cX9erVQ//+/XHy5Mk6+E6IyNpmTa1luCHSHLOHm2XLlmHKlCmYMWMGoqKiEBwcjIEDByI1NbXKz3F1dUVSUpLpOHfuXIWPz5kzB59//jkWLFiAvXv3wtnZWb5mfn6+ub8dIrISgzr6Qm9rg6MXshCXlqN0OUSkpnAzd+5cTJw4EePHj0e7du1kIHFycsK3335b5eeI1hofHx/T4e3tXaHV5tNPP8Ubb7yBYcOGoVOnTvj+++9x4cIFrF692tzfDhFZCQ9ne/Rp5SnP10az9YZIS8wabgoLCxEZGSm7jUxf0NZWPo6IiKjy83JyctCsWTP4+/vLAHP06FHTx86cOYPk5OQKr+nm5ia7u6p6zYKCAmRlZVU4iEj9hpoW9LsgfzEiIm0wa7hJT09HSUlJhZYXQTwWAaUyQUFBslVnzZo1+PHHH2EwGNCrVy8kJibKj5d/3vW85uzZs2UAKj9EaCIi9RvQ3gcOelucTs+V3VNEpA0WN1sqLCwMY8aMQUhICG699VasXLkSjRo1wv/93//d8GtOmzYNmZmZpiMhIaFWayYiy1TfQY872nrJcw4sJtIOs4YbT09P6HQ6pKSkVHhePBZjaWrCzs4OnTt3xqlTp+Tj8s+7ntd0cHCQg5SvPohIe11TBrFsMRGpnlnDjb29Pbp27YotW7aYnhPdTOKxaKGpCdGtdeTIETntW2jevLkMMVe/phhDI2ZN1fQ1iUg7bgvygouDHkmZ+XJRPyJSP7N3S4lp4AsXLsTixYtx7NgxTJ48Gbm5uXL2lCC6oES3Ubm3334bGzduxOnTp+XU8UceeUROBZ8wYYJpJtULL7yAd955B2vXrpXBR7yGn58fhg8fbu5vh4isjKOdTo69EdYeOq90OURUB/Tm/gIjR45EWlqaXHRPDPgVY2nCw8NNA4Lj4+PlDKpyly9fllPHxbUNGjSQLT+7d++W08jLTZ06VQakSZMmISMjA3369JGv+c/F/oiIhKEhfvg1KhEbjiRjxpD2sNNZ3HBDIqpFNkYNzo8U3Vhi1pQYXMzxN0TqV1xiQOh7W3AxtxCLxneXXVVEpN73b/76QkSqp9fZyhWLBc6aIlI/hhsi0gTRNSVsPJqC/KISpcshIjNiuCEiTejatAEau9dDTkExthyrem87IrJ+DDdEpAm2tjam1ps10Zw1RaRmDDdEpBnDysLN9uNpyMwrUrocIjIThhsi0ow2Pq5o4+OCwhIDfo9JUrocIjIThhsi0pT/dU1x1hSRWjHcEJEm95rac+YikjPzlS6HiMyA4YaINKVJAyd0D2gAsXyp2EyTiNSH4YaINGdoSGP55xruNUWkSgw3RKQ5gzv6Qm9rg5jzWTiVmqN0OURUyxhuiEhzPJztcUvrRvJ8Lde8IVIdhhsi0vSaN2sOXYAG9w8mUjWGGyLSpDvbeaOenQ7nLuYhOiFD6XKIqBYx3BCRJjnZ6zGgvbc855o3ROrCcENEmnVv59JZU2JKeFGJQelyiKiWMNwQkWb1CfSEZ317XMwtxJ8n05Quh4hqCcMNEWmWXmeLIWUrFq+M4qwpIrVguCEiTbuvcxP556a/U5Cdz53CidSA4YaINK1DY1e0bOSMgmKxU3iy0uUQUS1guCEiTbOxscF9XUpbb1YfZNcUkRow3BCR5pXvFB5x+iKSMq8oXQ4R3SSGGyLSPH8PJ/Ro7iF3CueaN0TWj+GGiOiqNW9WRZ3ndgxEVo7hhogIwKAOvrDX2eJ4SjaOJWUrXQ4R3QSGGyIiAG5OdrijrZc8X3UwUelyiOgmMNwQEZUZXtY1JcbdFHM7BiKrxXBDRFSmX5AXGjjZITW7ALtOpStdDhHdIIYbIqIy9npb07TwX7kdA5HVYrghIrrK/V1LF/TbeDQZmVe4HQORNWK4ISK6SsfGbmjtXV9ux7D+cJLS5RDRDWC4ISL6x3YM95dtx/BrFGdNEVkjhhsiokoW9LO1ASLPXcbptBylyyEiSww38+bNQ0BAABwdHREaGop9+/ZVee3ChQvRt29fNGjQQB79+/f/1/Xjxo2Tv11dfdx111118J0QkRZ4uTriltaN5PlKDiwmsjpmDzfLli3DlClTMGPGDERFRSE4OBgDBw5Eampqpddv374dDz30ELZt24aIiAj4+/tjwIABOH++4g8YEWaSkpJMx88//2zub4WINGRE2cDilVGJMBi4HQORNTF7uJk7dy4mTpyI8ePHo127dliwYAGcnJzw7bffVnr9kiVL8NRTTyEkJARt2rTBN998A4PBgC1btlS4zsHBAT4+PqZDtPIQEdWW/m294eqox4XMfLlbOBFZD7OGm8LCQkRGRsquJdMXtLWVj0WrTE3k5eWhqKgIHh4e/2rh8fLyQlBQECZPnoyLF6v+4VNQUICsrKwKBxFRdRztdLinfM2bSA4sJrImZg036enpKCkpgbe3d4XnxePk5OQavcarr74KPz+/CgFJdEl9//33sjXngw8+wI4dO3D33XfLr1WZ2bNnw83NzXSIri4iopp2Tf0ek4ycgmKlyyGiGtLDgr3//vtYunSpbKURg5HLjRo1ynTesWNHdOrUCS1btpTX3XHHHf96nWnTpslxP+VEyw0DDhFdS2d/d7TwdMbp9FxsOJKEB7vx5wYRtN5y4+npCZ1Oh5SUlArPi8dinEx1PvroIxluNm7cKMNLdVq0aCG/1qlTpyr9uBif4+rqWuEgIqrRmjdlrTcrDiQoXQ4RWUK4sbe3R9euXSsMBi4fHBwWFlbl582ZMwezZs1CeHg4unXrds2vk5iYKMfc+Pr61lrtRETlXVNizZv9Zy/jVCrXvCGyBmafLSW6g8TaNYsXL8axY8fk4N/c3Fw5e0oYM2aM7DYqJ8bQvPnmm3I2lVgbR4zNEUdOTukPFfHnK6+8gj179uDs2bMyKA0bNgyBgYFyijkRUW3ydnWUu4ULbL0hsg5mDzcjR46UXUzTp0+X07ujo6Nli0z5IOP4+Hi5Tk25+fPny1lWI0aMkC0x5Yd4DUF0cx0+fBhDhw5F69at8fjjj8vWoT///FN2PxER1bYHu/ubtmMoKjEoXQ4RXYON0WjU3OpUYkCxmDWVmZnJ8TdEdE0i0ITN3or0nAL836NdMbB99WMGiUjZ92/uLUVEdA12Olvc36WxPF++n11TRJaO4YaIqAYeKJsGvu14KlKy8pUuh4iqwXBDRFQDgV710T2gAcQ2U79wxWIii8ZwQ0RUQ+WL+C0/kMDNNIksGMMNEVENDe7ki/oOepy7mIe9Zy4pXQ4RVYHhhoiohpzs9RgS7GtqvSEiy8RwQ0R0A11TYq+pzLwipcshokow3BARXYcQf3e08XFBQbEBKw9yYDGRJWK4ISK6zs00R4c2ledL9sZDg+ugElWruMSA8JhkKInhhojoOg3v3BhO9jq5kabYUJOISolZhFN/PYwnf4zEJ5tOQCkMN0RE18nF0Q5Dg/3k+ZK955Quh8giGI1GTF8bg5VR56GztUE7P+W2N2K4ISK6AaNDm8k/fz+SjIs5BUqXQ6R4sJn9eyx+3BMPGxtg7oPBiu7BxnBDRHQDOjZxQ6cmbigsMXDFYtK8z7acxNc7T8vz9+/riGEhpXuxKYXhhojoBpUPLP5pXzxXLCbN+npnHD7dfFKezxjSDiO7l/5/oSSGGyKiGzQk2A8uZSsW7467qHQ5RHXuh4izeG9DrDx/ZWAQxvduDkvAcENEdBMrFt/XpbT5nQOLSWt+iUzEm2uOyvOnbmuJp/sFwlIw3BAR3YSHywYWb/w7BSlZ+UqXQ1Qn1h9OwtRfDsnzcb0CZKuNJWG4ISK6CUE+LujWrAFKDEYs28/9pkj9thxLwfNLD0IMMxvV3V+OsxGLW1oShhsiopv0SM9mpq6pohKD0uUQmc1fp9IxeUkUig1GDAvxw7v3drS4YCMw3BAR3aRBHX3hWd8BKVkF+OOossvOE5nLgbOXMGHxARQWGzCgnTc+eiBYLtZniRhuiIhukr3e1jQtfNFfZ5Uuh6jWHU7MwPjv9uNKUQluad0IXzzcGXY6y40QllsZEZEVEeFGb2uDA+cuI+Z8ptLlENWa2OQsjPl2H7ILitGjuQf+75GucNDrYMkYboiIaoGXqyMGd/KV54t2s/WG1CEuLQePfLMXGXlFCPF3x7fjuqOevWUHG4HhhoiologpscLa6AtI535TZOUSLuXJYJOeU4h2vq5YPL4H6jvoYQ0YboiIaknnpg0QXLbf1NJ98UqXQ3TDkjKv4OFv9iApMx+BXvXxw+M94OZkB2vBcENEVIvG9S5tvRG7I3NaOFmjtOwCjF64FwmXriCgoRN+mhCKhvUdYE0YboiIan1auD2Ss/I5LZyszqXcQtkVdTo9F43d62HJxJ5yPJm1YbghIqpFYhZJ+ZYMizmwmKxI5pUijPl2L46nZMPLxQE/TQyVAccaMdwQEdWyR8qmhe8/e1muD0Jk6XIKijH+u32IOZ+Fhs72Mtg0a+gMa8VwQ0RUy0Qz/pBgP3n+9c7TSpdDVK0rhSV4bNF+RMVnwK2eHX54PBSBXi6wZgw3RERmMLFvC/nnhiNJckotkSXKLyrBpB8OYN+ZS3Bx0OP7x3qgnZ8rrB3DDRGRGYg3iL6tPOXOyf/ddUbpcoj+RewR9fSSKPx5Mh1O9joseqw7gv3doQYMN0REZjLpltLWm2X7E5CRV6h0OUQmxSUGvLDsILbEpsJBb4v/ju2Ors08oBZ1Em7mzZuHgIAAODo6IjQ0FPv27av2+hUrVqBNmzby+o4dO2LDhg0VPm40GjF9+nT4+vqiXr166N+/P06ePGnm74KI6Pr0CfSUK7uKzQZ/3HNO6XKIpBKDES+tOIQNR5Jhr7PF12O6IaxlQ6iJ2cPNsmXLMGXKFMyYMQNRUVEIDg7GwIEDkZqaWun1u3fvxkMPPYTHH38cBw8exPDhw+URExNjumbOnDn4/PPPsWDBAuzduxfOzs7yNfPz88397RAR1ZiNjY2p9WbR7nNyfAORkgwGI1799TDWRF+QM/rmje6CW1s3gtrYGEUziBmJlpru3bvjyy+/lI8NBgP8/f3x7LPP4rXXXvvX9SNHjkRubi7WrVtneq5nz54ICQmRYUaU6+fnh5deegkvv/yy/HhmZia8vb2xaNEijBo16po1ZWVlwc3NTX6eq6v1D5wiIsslVim+dc42XMjMx/v3dcSoHk2VLok0ymg04j+rY/DT3njobG3wxUOd5aKT1qSm799mbbkpLCxEZGSk7DYyfUFbW/k4IiKi0s8Rz199vSBaZcqvP3PmDJKTkytcI75REaKqes2CggJ5Q64+iIjqgp3OFo/1aS7Pv/7ztPzNmUiJYPPWb3/LYGNjA8x9MNjqgs31MGu4SU9PR0lJiWxVuZp4LAJKZcTz1V1f/uf1vObs2bNlACo/RMsREVFdEa01Lo56nE7LxdbYyrvkicwZbGb/HotFZStmz7m/E4aFNIaaaWK21LRp02QTVvmRkJCgdElEpCH1HfR4OLS0O2r+jjj5ZkNUF4xGIz7847hpMcn37u2IB7qp/xd8s4YbT09P6HQ6pKSkVHhePPbx8an0c8Tz1V1f/uf1vKaDg4Psm7v6ICKqS4/3bg57vS0iz11GRNxFpcshjfhk80l8tT1Onr81tL0pZKudWcONvb09unbtii1btpieEwOKxeOwsLBKP0c8f/X1wqZNm0zXN2/eXIaYq68RY2jErKmqXpOIyBK2ZHioe+lvzJ9v5dIVZH5fbDmJz7eU/lt78552GNsrAFph9m4pMQ184cKFWLx4MY4dO4bJkyfL2VDjx4+XHx8zZozsNir3/PPPIzw8HB9//DFiY2Mxc+ZMHDhwAM8884xpauULL7yAd955B2vXrsWRI0fka4gZVGLKOBGRpXri1paw09lgz+lLcrl7InP5avspfLzphDyfdncbPF42qF0r9Ob+AmJqd1pamlx0Twz4FVO6RXgpHxAcHx8vZ1CV69WrF3766Se88cYbeP3119GqVSusXr0aHTp0MF0zdepUGZAmTZqEjIwM9OnTR76mWPSPiMhS+bnXw4iu/vh5Xzy+2HpSblBIVNu+3hmHOeHH5fkrA4NkqNYas69zY4m4zg0RKUVsotnvo+0oNhix6qle6Ny0gdIlkYp88+dpvLP+mDx/oX8rvNC/NdTEIta5ISKiivw9nHBv59JpuF9sPaV0OaQiYoPW8mDz3B3qCzbXg+GGiKiOPd0vELY2kGvexJzPVLocUoHv/jqDWev+lufP3h6IF/u3gpYx3BAR1bEAT2cMDfaT5+WzWYhu1PcRZ+Xqw8LT/Vpiyp2t5eQbLWO4ISJSwDO3B8pl8Df+nYK/L3BLGLoxi3efxfQ1R+X55Nta4uUBQZoPNgLDDRGRAgK9XHBPp9LWm482ls5sIboei/46gxlrS4PNE7e2wNSBDDblGG6IiBQiug/E7sxi7M3+s1z3hmru211nMLOsK0q02Lx2VxsGm6sw3BARKaS5pzNGlq1a/MHvsdxzimo8K+rtdf8bY8MWm39juCEiUtDzd7SCg94WB85dxrbj3DGcrr2OTfmsqGf6BXKMTRUYboiIFOTt6ojxvUuXxheryhoMbL2hys3fHmdax0ZM935pAGdFVYXhhohIYZNvbQkXRz1ik7Ox9tAFpcshCySWDPggPNa08jCne1eP4YaISGFuTnZ4smz/n483HUdhsUHpkshCiHFYczcex9yyTTDFXlFi5WEGm+ox3BARWYDxvQPQyMUBCZeuYOn+eKXLIQsJNnP+OI7Py7bpeH1QG7m6NV0bww0RkQVwstfL/YCEzzafROaVIqVLIoWDjZgRJcbZCNPvaYdJt2hvd+8bxXBDRGQhRnX3R8tGzriYW4gvuC2DZolB5a+visF3f52Vj2cN74DH+pQOOqeaYbghIrIQdjpbTB/SXp4v2n0Wp1JzlC6J6lhxiQEvrTiEn/fFy81VPxzRCY/2bKZ0WVaH4YaIyILc2roR7mjjhWKDEe+sL13PhLRBDCR/9ueDWHXwvFy5+rNRnfFAt9JFHun6MNwQEVmYN+5pBzudDbYfT8PW2BSly6E6cKWwBE/8cAC/xyTDXmeL+aO7YEjZzvF0/RhuiIgscFuGx8oW9pu17hinhqtcdn4Rxn63D9uOp8HRzhYLx3bDgPY+Spdl1RhuiIgs0DO3B8KzvgPOpOdi8e7SgaWkPhdzCvDQwj3Yd+YSXBz0+OHxUNk1STeH4YaIyAK5ONph6l1B8vyzLSeRll2gdElUy5Iyr+DB/4tAzPksNHS2x8+TeqJ7gIfSZakCww0RkYUa0aUJgpu4Iaeg2LQLNKmDaJEbMT8CcWm58HVzxPInw9ChsZvSZakGww0RkYWytbXBO8M7yinBvx26gC3HOLhYDY4kZmLE/N04n3EFAQ2dsOLJMLRsVF/pslSF4YaIyIJ1bOKGCX1byPM3VsfIVhyyXn+dSseoryPkQo3t/Vyx4sleaNLASemyVIfhhojIwr3YvzWaejghKTMfc8p2hibrs/5wEsZ/tx+5hSUIa9EQSyf1lPuJUe1juCEisnD17HWYfV9Hef7DnnM4cPaS0iXRdRJ/b8/8HIXCEgPu7uCD78Z3l4PGyTwYboiIrEDvQE882K0JjEbgtZVHUFBconRJVMN9oj4Ij8Wbq2Pk393DoU3x5cNd4GinU7o0VWO4ISKyEq8PaivXvhF7Ts3bekrpcugaxOKLU5ZHm3b2fqF/K7w7vIPcWoHMi+GGiMhKuDvZ462hpRtrztseh4Pxl5UuiaqQlV+Ecd/tw+roC9Db2mDOiE54oX9r2Ngw2NQFhhsiIisyqKMP7unkixKDEc8vjebsKUtdnG9BBHbHXYSzvQ7/HdcdD3IDzDrFcENEZEXEb/7v3tsRjd3rIf5SHqaviVG6JLrK4cQMDPvyL8QmZ8uZUMueCON2CgpguCEisjJu9ezw6agQubjfyqjzWBN9XumSCEB4TJLcTiE1uwBB3i5Y9VQvrjqsEIYbIiIrJPYgevb2VvL8jVUxSLiUp3RJmmU0GrFgRxye/DEK+UUG3BbUCL9MDuPifApiuCEislLP3h6Irs0aILugGM8vPYjiEoPSJWmOmJL/6q+H8f7vpYsrjg1rhm/GdOMaNmoNN5cuXcLo0aPh6uoKd3d3PP7448jJyan2+meffRZBQUGoV68emjZtiueeew6ZmZn/6m/+57F06VJzfRtERBZLr7PFpyND4OKgR1R8Bj7ceFzpkjQlNSsfD329B8sPJMouwplD2uGtYR3k3wspy2x/AyLYHD16FJs2bcK6deuwc+dOTJo0qcrrL1y4II+PPvoIMTExWLRoEcLDw2Uo+qfvvvsOSUlJpmP48OHm+jaIiCyav4cTZt9funrx/+04zfE3deRQQgaGfvmXDJWujnp8N74HxvVurnRZVMbGKDoLa9mxY8fQrl077N+/H926dZPPiaAyaNAgJCYmws/Pr0avs2LFCjzyyCPIzc2FXq8vLdjGBqtWrbqpQJOVlQU3NzfZKiRaloiIrJ3oFhHjPhz0tnKX6U5N3JUuSbVWRiXKVaLFIn2BXvWxcEw3NPd0VrosTciq4fu3WVpuIiIiZFdUebAR+vfvD1tbW+zdu7fGr1NefHmwKff000/D09MTPXr0wLfffisHc1WnoKBA3pCrDyIiNXllYBBub+OFgmIDnvghEqnZ+UqXpDoizMxcexRTlh+S5/3beskZUQw2lscs4SY5ORleXl4VnhMBxcPDQ36sJtLT0zFr1qx/dWW9/fbbWL58uezuuv/++/HUU0/hiy++qPa1Zs+eLZNe+eHvz8WUiEhdxJL+Ynp4i0bOcvfwyT9Gcf+pWl6Yb9TXEVi0+6x8/Ey/QHz9KAcOqyLcvPbaa5UO6L36iI0tHTF+M0TLyuDBg2XX1syZMyt87M0330Tv3r3RuXNnvPrqq5g6dSo+/PDDal9v2rRpshWo/EhISLjpGomILI2ro13ZTB09Is9dLtussdZHHmjOX6fSMfjzXXJ8jbi3ohvq5YFBsOUeURarYn/PNbz00ksYN25ctde0aNECPj4+SE1NrfB8cXGxnBElPlad7Oxs3HXXXXBxcZFja+zsqk/FoaGhsoVHdD05ODhUeo14vqqPERGpSYtG9fHFQ53x2KL9chaPl4ujfCOm6ye2uJi//RTmbjoBgxFo5+uK+Y90QbOG7IZSVbhp1KiRPK4lLCwMGRkZiIyMRNeuXeVzW7duhcFgkGGkuhabgQMHyiCydu1aODo6XvNrRUdHo0GDBgwvRERlbgvywtvDOuCN1TH4ctsp2drwxK0tlS7LqiRn5uPFZdGIOH1RPh7ZzR9vDWsPRzud0qVRbYebmmrbtq1sfZk4cSIWLFiAoqIiPPPMMxg1apRpptT58+dxxx134Pvvv5cDg0WwGTBgAPLy8vDjjz9WGPgrApVOp8Nvv/2GlJQU9OzZUwYfMe7mvffew8svv2yOb4OIyGo90rMZsvOL8UF4LGb/HgvXenZ4qEdTpcuyCpv+TsHUXw7hcl4RnOx1cif2B7jxpVUxS7gRlixZIgONCDBilpQY/Pv555+bPi4Cz/Hjx2WYEaKiokwzqQIDAyu81pkzZxAQECC7qObNm4cXX3xR9iOL6+bOnStDFBERVTT5tpbIyi/C/O1xeH3VETg76DE0uGZLcWhRflEJ3ttwDN9HnJOPOzR2xeejOsuuPrIuZlnnxtJxnRsi0grxI150Ty3ZGw+9rQ3mje6Cge2rH/uoRQfjL+PlFYcQl5YrH0/s21yOVXLQsxvKkii6zg0REVkGMYt11rAOGBbih2KDEZN/jMSy/fFKl2UxxHR50XV3//zdMtg0cnHAovHd8Z/B7RhsrJjZuqWIiMgyiCnLHz8QDHudLVZEJuLVX48gPacQT93WUoYfrTqSmImXVkTjRErpvofDQ/wwc2h7uDvZK10a3SSGGyIiDRCbOc4Z0Um2THy1PQ4f/nEcadkFmH5PO82t15JTUIxPNp3Ad3+dkVO8Pevb453hHXFXB3bXqQXDDRGRRohWmql3tYFnfQe8ve5vudpuWk4BPhoRjHr2Ok2MPwqPScZbv/2N5KzS7Snu6eQrp817OLO1Rk0YboiINOaxPs3RsL69HEC7/nASTqZk46vRXRDo5QK1Opuei5m/HcX242nycbOGTjLU3Nr62mu3kfVhuCEi0qBhIY3l6sXP/nxQjjkZ+uVfePfeDri3cxOoyaXcQny+5SSW7D2HohKjHHf05G0t5XgjLsinXpwKzqngRKRhYvfwF5ZGY3dc6Uq8o7r7y0G11v7GL9asEd1u87adkosZCqKVZsaQdly3RgPv3ww3DDdEpHFiDyXRuvH51pMQ7wiiy0YEnH5BXrDGULPiQIJcuPBCZum4GrEn1OuD2qJPK0+ly6ObxHBTDYYbIqLKd7+esjwaKVkF8vHA9t6YPqQ9GrvXg6XLLSjGT3vj8fWfp+UsMMHXzREvDwjCvZ0ba25GmFox3FSD4YaIqOpp0p9tPoFv/zorW3Tq2enwzO2BGNcrQG7fYGkuZFzB0n3x+GHPObkXlODn5ijH1TzYzd/qu9eoIoabajDcEBFV73hyNt5cHYN9Zy/Jx2717DAmrBnG9gqQU8mVJELXzpNpWLInHltjU+RaNYLoThMDhcWgaHs9F+BXI4abajDcEBFdm3h7WB19Hp9tPomzF0s3OXbQ2+KBbk3waM8AtPauX2crHBsMRkQnZsh1asT09fMZV0wf69nCQ+6Cfld7H7lYIakXw001GG6IiK6vpWTj0WQs2BGHQ4mZpudbNnLGoI6+uLuDL9r6utR60MnOL0JUfAa2xabKUFO+8F55S9KIrk3wUI+mCPTi7CetyGK4qRrDDRHR9RNvF3tOX8J/d53BzhNpKCwxmD7W1MMJXZq6o0NjN3Rq4o72fq7XNUYnK78I8RfzEJeWg8hzl7H/7GUcT84ydTkJ9R30uL2Nl9wmQfzJ8TTaw3BTDYYbIqKbI8LI1mOp2HAkCdtF0Cn+X9ARRCOOt4sjGjjbo6GzvdzeQLS2FBsMKCgyoKCk9E+x/UP8xVzTYOB/EqEptLmHDDS9Az0ZaDQui+Gmagw3RES1O8Nq/5lLOHI+s/RIzKzQhVRTYgNLEWZEy0/3AA90C2gAb1dHs9RM6n7/trx5fUREZFVEd1G/Nl7yKCfWmknKvIKLuYW4nFsot0HIulIEO50tHOxs4aDXycHJ7k52aOrhjKYNneTrENUG/ksiIqJa18jFQR5ESuCcOSIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVTe4KbjQa5Z9ZWVlKl0JEREQ1VP6+Xf4+XhVNhpvs7Gz5p7+/v9KlEBER0Q28j7u5uVX5cRvjteKPChkMBly4cAEuLi6wsbGp9VQpQlNCQgJcXV1r9bXpf3if6wbvc93gfa4bvM/Wf59FZBHBxs/PD7a2VY+s0WTLjbghTZo0MevXEH+h/J/H/Hif6wbvc93gfa4bvM/WfZ+ra7EpxwHFREREpCoMN0RERKQqDDe1zMHBATNmzJB/kvnwPtcN3ue6wftcN3iftXOfNTmgmIiIiNSLLTdERESkKgw3REREpCoMN0RERKQqDDdERESkKgw312nevHkICAiAo6MjQkNDsW/fvmqvX7FiBdq0aSOv79ixIzZs2FBntWrpXi9cuBB9+/ZFgwYN5NG/f/9r/t3Qjf2bLrd06VK5wvfw4cPNXqMW73NGRgaefvpp+Pr6ylknrVu35s8PM9znTz/9FEFBQahXr55cVffFF19Efn5+ndVrjXbu3IkhQ4bIVYLFz4DVq1df83O2b9+OLl26yH/LgYGBWLRokXmLFLOlqGaWLl1qtLe3N3777bfGo0ePGidOnGh0d3c3pqSkVHr9X3/9ZdTpdMY5c+YY//77b+Mbb7xhtLOzMx45cqTOa1f7vX744YeN8+bNMx48eNB47Ngx47hx44xubm7GxMTEOq9dzfe53JkzZ4yNGzc29u3b1zhs2LA6q1cr97mgoMDYrVs346BBg4y7du2S93v79u3G6OjoOq9dzfd5yZIlRgcHB/mnuMd//PGH0dfX1/jiiy/Wee3WZMOGDcb//Oc/xpUrV4rZ1sZVq1ZVe/3p06eNTk5OxilTpsj3wi+++EK+N4aHh5utRoab69CjRw/j008/bXpcUlJi9PPzM86ePbvS6x988EHj4MGDKzwXGhpqfOKJJ8xeq9bu9T8VFxcbXVxcjIsXLzZjldq8z+Le9urVy/jNN98Yx44dy3Bjhvs8f/58Y4sWLYyFhYV1WKX27rO49vbbb6/wnHgD7t27t9lrVQvUINxMnTrV2L59+wrPjRw50jhw4ECz1cVuqRoqLCxEZGSk7O64eo8q8TgiIqLSzxHPX329MHDgwCqvpxu/1/+Ul5eHoqIieHh4mLFSbd7nt99+G15eXnj88cfrqFLt3ee1a9ciLCxMdkt5e3ujQ4cOeO+991BSUlKHlav/Pvfq1Ut+TnnX1enTp2XX36BBg+qsbi2IUOC9UJMbZ96I9PR0+YNF/KC5mngcGxtb6eckJydXer14nmr3Xv/Tq6++KvuD//k/FN3cfd61axf++9//Ijo6uo6q1OZ9Fm+yW7duxejRo+Wb7alTp/DUU0/JwC5WfqXauc8PP/yw/Lw+ffrI3aaLi4vx5JNP4vXXX6+jqrUhuYr3QrF7+JUrV+R4p9rGlhtSnffff18Odl21apUcVEi1Izs7G48++qgcvO3p6al0OapmMBhk69jXX3+Nrl27YuTIkfjPf/6DBQsWKF2aqohBrqJF7KuvvkJUVBRWrlyJ9evXY9asWUqXRjeJLTc1JH6Y63Q6pKSkVHhePPbx8an0c8Tz13M93fi9LvfRRx/JcLN582Z06tTJzJVq6z7HxcXh7NmzcpbE1W/Cgl6vx/Hjx9GyZcs6qFz9/57FDCk7Ozv5eeXatm0rfwMW3S/29vZmr1sL9/nNN9+UgX3ChAnysZjRmpubi0mTJskwKbq16OZV9V7o6upqllYbgX9zNSR+mIjfoLZs2VLhB7t4LPrGKyOev/p6YdOmTVVeTzd+r4U5c+bI37jCw8PRrVu3OqpWO/dZLGlw5MgR2SVVfgwdOhT9+vWT52IaLdXOv+fevXvLrqjy8CicOHFChh4Gm9q7z2Js3j8DTHmg5LaLtUeR90KzDVVW6TRDMW1w0aJFcjrbpEmT5DTD5ORk+fFHH33U+Nprr1WYCq7X640fffSRnJ48Y8YMTgU3071+//335RTQX375xZiUlGQ6srOzFfwu1Hef/4mzpcxzn+Pj4+Vsv2eeecZ4/Phx47p164xeXl7Gd955R8HvQn33WfxMFvf5559/ltOVN27caGzZsqWc6UpVEz9XxbIb4hAxYu7cufL83Llz8uPiHot7/c+p4K+88op8LxTLdnAquIUR8/ObNm0q30jFtMM9e/aYPnbrrbfKH/ZXW758ubF169byejEVbv369QpUrf573axZM/k/2T8P8cOLavff9NUYbsx3n3fv3i2XjhBv1mJa+Lvvviun4VPt3eeioiLjzJkzZaBxdHQ0+vv7G5966inj5cuXFareOmzbtq3Sn7fl91b8Ke71Pz8nJCRE/r2If8/fffedWWu0Ef8xX7sQERERUd3imBsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIlIVhhsiIiJSFYYbIiIiUhWGGyIiIoKa/D/cz8GinxxMEgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dezero import Variable\n",
    "import dezero.functions as F\n",
    "\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(100, 1)\n",
    "y = np.sin(2*np.pi*x) + np.random.rand(100, 1)\n",
    "\n",
    "# initialize weights\n",
    "I, H, O = 1, 10, 1 # input hidden output layers\n",
    "W1 = Variable(0.01 * np.random.randn(I, H))\n",
    "b1 = Variable(np.zeros(H))\n",
    "\n",
    "W2 = Variable(0.01 * np.random.randn(H, O))\n",
    "b2 = Variable(np.zeros(O))\n",
    "\n",
    "def predict(x):\n",
    "    y = F.linear(x, W1, b1)\n",
    "    y = F.sigmoid_simple(y)\n",
    "    y = F.linear(y, W2, b2)\n",
    "    return y\n",
    "\n",
    "lr = 0.2\n",
    "iters = 10000\n",
    "\n",
    "for i in range(iters):\n",
    "    y_pred = predict(x)\n",
    "    loss = F.mean_squared_error(y, y_pred)\n",
    "    W1.cleargrad()\n",
    "    b1.cleargrad()\n",
    "    W2.cleargrad()\n",
    "    b2.cleargrad()\n",
    "    loss.backward()\n",
    "\n",
    "    W1.data -= lr*W1.grad.data\n",
    "    b1.data -= lr*b1.grad.data\n",
    "    W2.data -= lr*W2.grad.data\n",
    "    b2.data -= lr*b2.grad.data\n",
    "    if i % 1000 == 0:\n",
    "        print(loss)\n",
    "\n",
    "# plot to check how well the nn fit to toy sin() data\n",
    "import matplotlib.pyplot as plt\n",
    "x_t = np.linspace(0,1,100).reshape(100,1)\n",
    "y_pred = predict(x_t).data\n",
    "\n",
    "# pretty well indeed\n",
    "plt.plot(x_t, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Layer` class test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p1', 'p2'}\n",
      "p1 variable(1)\n",
      "p2 variable(2)\n"
     ]
    }
   ],
   "source": [
    "# layer class\n",
    "import numpy as np\n",
    "from dezero import Variable\n",
    "import dezero.functions as F\n",
    "from dezero import Parameter\n",
    "from dezero.layers import Layer\n",
    "\n",
    "layer = Layer()\n",
    "layer.p1 = Parameter(np.array(1))\n",
    "layer.p2 = Parameter(np.array(2))\n",
    "layer.p3 = Variable(np.array(3))\n",
    "layer.p4 = 'test'\n",
    "\n",
    "print(layer._params)\n",
    "'''\n",
    "out:\n",
    "{'p2', 'p1'}\n",
    "'''\n",
    "\n",
    "for name in layer._params:\n",
    "    print(name, layer.__dict__[name])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Linear类实现神经网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable([0. 0. 0. 0. 0.])\n",
      "variable(None)\n",
      "variable([0. 0. 0.])\n",
      "variable(None)\n",
      "variable(2.1085010410910483)\n",
      "variable(0.7830999831433312)\n",
      "variable(0.741839976546367)\n",
      "variable(0.7344466963310486)\n",
      "variable(0.7282170690813982)\n",
      "variable(0.7219737288013254)\n",
      "variable(0.7151031894262673)\n",
      "variable(0.7072330611350139)\n",
      "variable(0.6981425150188675)\n",
      "variable(0.6877230785745242)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "import numpy as np\n",
    "from dezero import Variable, Layer\n",
    "from dezero.models import Model\n",
    "import dezero.functions as F\n",
    "import dezero.layers as L\n",
    "\n",
    "\n",
    "# toy data\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(100,1)\n",
    "y = np.sin(2*np.pi*x) + np.random.rand(100,1)\n",
    "\n",
    "# (old)assign out_size to Linear layer\n",
    "# l1 = L.Linear(10)\n",
    "# l2 = L.Linear(1)\n",
    "\n",
    "# 将Layer作为参数加入Layer的_params中后，我们就可以把作为Layer的Linear实例（L.Linear)传入Layer的实例model的_params中统一管理\n",
    "model = Layer()\n",
    "model.l1 = L.Linear(5)\n",
    "model.l2 = L.Linear(3)\n",
    "\n",
    "# 定义网络结构：\n",
    "def predict(model, x):\n",
    "    # 所有的参数都在model中统一管理\n",
    "    y = model.l1(x)\n",
    "    y = F.sigmoid_simple(y)\n",
    "    y = model.l2(y)\n",
    "    return y\n",
    "\n",
    "# 测试访问所有参数并重置所有参数的梯度：\n",
    "for p in model.params():\n",
    "    #由于params()是yield构造的生成器，因此需要逐个访问\n",
    "    print(p)\n",
    "\n",
    "model.cleargrads()\n",
    "\n",
    "lr = 0.2\n",
    "iters = 1000\n",
    "\n",
    "for i in range(iters):\n",
    "    y_pred = predict(model, x)\n",
    "    loss = F.mean_squared_error(y, y_pred)\n",
    "\n",
    "    # l1.cleargrads()\n",
    "    # l2.cleargrads()\n",
    "    model.cleargrads()\n",
    "    loss.backward()\n",
    "\n",
    "    \n",
    "    for p in model.params():\n",
    "        p.data -= lr*p.grad.data\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将上面的步骤抽象为一种更便捷的方法：将模型定义为一个继承Layer类的类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmd: cd /d D:\\graphviz\\bin&dot C:\\Users\\xuguy\\.dezero\\tmp_graph.dot -T png -o model.png\n",
      "variable(2.1085010410910483)\n",
      "variable(0.7830999831433312)\n",
      "variable(0.741839976546367)\n",
      "variable(0.7344466963310488)\n",
      "variable(0.7282170690813982)\n",
      "variable(0.7219737288013254)\n",
      "variable(0.7151031894262673)\n",
      "variable(0.7072330611350139)\n",
      "variable(0.6981425150188673)\n",
      "variable(0.6877230785745243)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class TwoLayerNet(Model):\n",
    "    def __init__(self, hidden_size, out_size):\n",
    "        super().__init__()\n",
    "        self.l1 = L.Linear(hidden_size)\n",
    "        self.l2 = L.Linear(out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #定义模型的网络结构\n",
    "        y = F.sigmoid(self.l1(x))\n",
    "        y = self.l2(y)\n",
    "        return y\n",
    "\n",
    "# toy data: our old friend sin()\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(100,1)\n",
    "y = np.sin(2*np.pi*x) + np.random.rand(100,1)\n",
    "\n",
    "hidden_size = 5\n",
    "out_size = 3\n",
    "lr = 0.2\n",
    "iters = 1000\n",
    "model = TwoLayerNet(hidden_size,out_size)\n",
    "model.plot(x)\n",
    "# model.cleargrads()\n",
    "\n",
    "for i in range(iters):\n",
    "    #forward\n",
    "    y_pred = model(x)\n",
    "    # cal loss\n",
    "    loss = F.mean_squared_error(y, y_pred)\n",
    "    #cleargrads before backwards\n",
    "    model.cleargrads()\n",
    "    loss.backward()\n",
    "    #更新模型参数\n",
    "    for p in model.params():\n",
    "        p.data -= lr*p.grad.data\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试 MLP模型\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable([[0.07108538]\n",
      "          [0.07161369]\n",
      "          [0.0712646 ]\n",
      "          [0.07107203]\n",
      "          [0.07064234]\n",
      "          [0.07140248]\n",
      "          [0.07069343]\n",
      "          [0.07209376]\n",
      "          [0.07226566]\n",
      "          [0.07049259]\n",
      "          [0.071832  ]\n",
      "          [0.07101736]\n",
      "          [0.07115011]\n",
      "          [0.07217629]\n",
      "          [0.06924527]\n",
      "          [0.06931165]\n",
      "          [0.06903548]\n",
      "          [0.07194221]\n",
      "          [0.07179445]\n",
      "          [0.07203908]\n",
      "          [0.07229976]\n",
      "          [0.07185237]\n",
      "          [0.07078005]\n",
      "          [0.07180105]\n",
      "          [0.06943986]\n",
      "          [0.07138367]\n",
      "          [0.06954276]\n",
      "          [0.07222153]\n",
      "          [0.07099306]\n",
      "          [0.07060914]\n",
      "          [0.07003226]\n",
      "          [0.0717835 ]\n",
      "          [0.07076084]\n",
      "          [0.07115141]\n",
      "          [0.06902959]\n",
      "          [0.07131269]\n",
      "          [0.07129485]\n",
      "          [0.07131044]\n",
      "          [0.07221937]\n",
      "          [0.07151358]\n",
      "          [0.07040193]\n",
      "          [0.0706914 ]\n",
      "          [0.07156138]\n",
      "          [0.06920065]\n",
      "          [0.07146744]\n",
      "          [0.07147937]\n",
      "          [0.06981541]\n",
      "          [0.06948361]\n",
      "          [0.07023218]\n",
      "          [0.07041793]\n",
      "          [0.0711573 ]\n",
      "          [0.07069713]\n",
      "          [0.0723217 ]\n",
      "          [0.0693731 ]\n",
      "          [0.06980933]\n",
      "          [0.06961617]\n",
      "          [0.07142506]\n",
      "          [0.06998748]\n",
      "          [0.07079741]\n",
      "          [0.06995212]\n",
      "          [0.06960662]\n",
      "          [0.06940738]\n",
      "          [0.0714351 ]\n",
      "          [0.06952158]\n",
      "          [0.06975961]\n",
      "          [0.07043697]\n",
      "          [0.07191133]\n",
      "          [0.06935274]\n",
      "          [0.07195623]\n",
      "          [0.06934861]\n",
      "          [0.07229487]\n",
      "          [0.0708058 ]\n",
      "          [0.07229556]\n",
      "          [0.07127137]\n",
      "          [0.07168406]\n",
      "          [0.0691138 ]\n",
      "          [0.07010444]\n",
      "          [0.06944776]\n",
      "          [0.07015685]\n",
      "          [0.06944173]\n",
      "          [0.07024211]\n",
      "          [0.07060767]\n",
      "          [0.06921684]\n",
      "          [0.07154586]\n",
      "          [0.07114529]\n",
      "          [0.07003557]\n",
      "          [0.0709979 ]\n",
      "          [0.06933972]\n",
      "          [0.07117644]\n",
      "          [0.07218514]\n",
      "          [0.07024438]\n",
      "          [0.07146943]\n",
      "          [0.06949539]\n",
      "          [0.07161705]\n",
      "          [0.07013042]\n",
      "          [0.06970529]\n",
      "          [0.0712114 ]\n",
      "          [0.06903503]\n",
      "          [0.07193247]\n",
      "          [0.06897144]])\n",
      "0-(40,): variable([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "          0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.])\n",
      "1-(30, 40): variable([[-0.11815863  0.08622014  0.16986857 ... -0.04739206  0.06654487\n",
      "            0.26862541]\n",
      "          [ 0.29079881 -0.04720869  0.05629333 ...  0.2865063   0.12605452\n",
      "            0.14545176]\n",
      "          [-0.12012032  0.17689296  0.04118539 ... -0.33193405 -0.0090053\n",
      "            0.04364136]\n",
      "          ...\n",
      "          [ 0.23182627 -0.12960105  0.0031979  ... -0.08778995  0.12845656\n",
      "            0.16963792]\n",
      "          [ 0.06776653 -0.18071605  0.11751046 ...  0.23240849 -0.30966978\n",
      "            0.13331267]\n",
      "          [-0.3391285   0.06985254 -0.16192583 ...  0.23397088  0.34948894\n",
      "           -0.30416056]])\n",
      "2-(1,): variable([0.])\n",
      "3-(40, 1): variable([[ 2.57195887e-01]\n",
      "          [-3.34313303e-02]\n",
      "          [-2.37251265e-03]\n",
      "          [-1.79319528e-02]\n",
      "          [ 1.70849026e-01]\n",
      "          [-2.54195994e-01]\n",
      "          [ 7.21258005e-02]\n",
      "          [-1.49397092e-01]\n",
      "          [ 9.02495865e-02]\n",
      "          [ 2.43937525e-01]\n",
      "          [-6.59850980e-05]\n",
      "          [ 5.91591117e-02]\n",
      "          [ 6.47558206e-02]\n",
      "          [-1.26426834e-01]\n",
      "          [ 2.39011168e-01]\n",
      "          [ 2.69816317e-01]\n",
      "          [ 1.10961692e-01]\n",
      "          [ 1.15874440e-02]\n",
      "          [-7.30318265e-02]\n",
      "          [-9.90568038e-02]\n",
      "          [ 2.70507007e-01]\n",
      "          [ 2.23638648e-01]\n",
      "          [-1.00657647e-02]\n",
      "          [-2.49808953e-01]\n",
      "          [-4.47780404e-01]\n",
      "          [-1.71304805e-01]\n",
      "          [-2.06528971e-02]\n",
      "          [ 2.21468378e-01]\n",
      "          [-1.03035894e-01]\n",
      "          [ 7.98183325e-02]\n",
      "          [ 2.06050998e-01]\n",
      "          [ 2.03233757e-02]\n",
      "          [-2.25229865e-02]\n",
      "          [-2.06933680e-01]\n",
      "          [-1.90128040e-01]\n",
      "          [ 6.57911294e-02]\n",
      "          [-3.17662694e-02]\n",
      "          [ 1.93739023e-02]\n",
      "          [-7.47526311e-03]\n",
      "          [ 1.05010393e-01]])\n",
      "4-(30,): variable([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "          0. 0. 0. 0. 0. 0.])\n",
      "5-(20, 30): variable([[-1.40444653e-01 -1.07560935e-01  5.15171434e-01 -2.37026738e-01\n",
      "           -3.03992773e-02  2.54216638e-01  2.18519669e-02  1.30352408e-01\n",
      "           -8.93195164e-02  8.27470112e-02 -2.92148296e-01  3.70769284e-01\n",
      "           -2.64222843e-02 -1.52092475e-01  1.49007788e-01 -1.03020078e-01\n",
      "           -2.98349257e-01 -3.01135182e-01  1.55132393e-01 -3.56817050e-02\n",
      "           -2.98965783e-02  2.40990833e-01 -2.51965911e-01 -1.63384506e-01\n",
      "           -8.60617391e-02  2.10976568e-02 -9.42982338e-03 -6.41499278e-02\n",
      "           -1.37800821e-02 -2.39941886e-02]\n",
      "          [-1.60908429e-01 -1.81790759e-01  6.13837206e-02 -1.99214672e-01\n",
      "           -2.58792514e-01 -6.98306695e-02 -3.52554154e-02  5.04618694e-01\n",
      "           -1.57575775e-01  2.10919511e-01  1.67076390e-01 -2.65856170e-01\n",
      "            1.72904619e-01 -2.64723769e-01 -5.94609002e-01  1.35577172e-01\n",
      "           -3.92629076e-01  1.00832013e-01 -1.52949492e-01  3.71086837e-01\n",
      "            2.38925952e-01 -1.01380147e-01 -1.53805163e-01 -2.71475949e-01\n",
      "           -9.85932946e-02 -6.26893919e-02 -8.15479574e-02  3.50400482e-02\n",
      "            1.29361338e-01  7.81851154e-02]\n",
      "          [-1.70867780e-01 -3.21499946e-01  3.05118603e-01 -1.54165526e-01\n",
      "           -1.45857288e-01 -1.16541478e-01 -4.12122881e-01 -1.06878235e-01\n",
      "           -1.07254298e-01  1.38716330e-01  1.56179760e-01  8.43196418e-04\n",
      "            2.08367625e-01  7.60184818e-02 -3.50662694e-03  3.59846338e-02\n",
      "           -4.26314159e-02 -8.82910343e-02 -5.98670404e-02 -2.52231005e-01\n",
      "            6.27086708e-02 -2.22069186e-01  1.88194478e-01 -5.57806345e-02\n",
      "            1.10674144e-02  1.10425263e-01  1.43849491e-01 -3.51202068e-01\n",
      "           -4.62650696e-02  1.96813992e-01]\n",
      "          [-3.79708003e-01  8.65985444e-02 -5.04359491e-01 -2.28639479e-01\n",
      "            8.63805416e-03 -3.70452771e-01 -2.20366907e-01 -3.29112315e-01\n",
      "            3.68534178e-01  3.67224421e-02  1.26849969e-01 -4.97916660e-02\n",
      "           -7.90297444e-02 -3.61454609e-01 -6.52568185e-02 -1.70274831e-01\n",
      "            1.91837622e-01  2.55158128e-01  3.27936972e-01  1.90636409e-01\n",
      "           -1.33863084e-01 -2.49522141e-01  1.71431102e-01  7.96694952e-02\n",
      "           -3.95457225e-01  7.94881477e-02  1.82132169e-01  1.31761620e-02\n",
      "           -4.13792600e-02 -1.80595690e-01]\n",
      "          [-3.23455004e-01  1.78952068e-01 -6.91200937e-02 -5.22047311e-02\n",
      "            3.87448241e-01  1.53059102e-01  8.29189891e-02  3.17659841e-02\n",
      "            3.39881182e-01  3.84511869e-01  2.07843661e-01  1.30189380e-01\n",
      "           -4.68367483e-01  2.76650607e-02 -2.90927997e-02  2.10085808e-02\n",
      "            2.10871517e-01 -6.12610443e-01 -1.27302041e-01  6.03524463e-02\n",
      "           -1.04389837e-01 -3.16829840e-01  1.94306141e-01  6.19104433e-02\n",
      "           -2.17145581e-01  7.03952638e-02  1.83712151e-01  1.18347165e-03\n",
      "            1.79011737e-01  1.74995073e-02]\n",
      "          [-8.83758870e-02 -2.59254303e-01 -1.92147031e-02  4.34452205e-02\n",
      "            1.95842154e-01 -2.57388126e-02  1.02281240e-01 -2.15693802e-01\n",
      "           -1.75001194e-01 -2.46837978e-02 -2.35822100e-01  1.83412990e-01\n",
      "            1.03559089e-01  6.24077112e-02  7.57812634e-02  4.51919074e-01\n",
      "           -1.04841223e-01 -4.92257237e-01  4.45648795e-02 -1.13152961e-02\n",
      "           -1.15720779e-01 -2.18873011e-01 -9.82057629e-02  4.05485055e-02\n",
      "           -1.12433227e-01  5.39441036e-01 -2.14775303e-01 -1.77346430e-01\n",
      "           -5.11750988e-01  5.62336267e-02]\n",
      "          [-4.50882208e-01 -1.20625724e-01 -6.16418041e-02 -1.58699993e-01\n",
      "            3.88823744e-01  2.22353339e-01  2.94967969e-01 -1.97314845e-01\n",
      "            2.52361299e-01  1.10909183e-01  1.72491611e-01  2.30189525e-01\n",
      "           -2.03205636e-01 -9.48803061e-02  1.92882337e-01 -5.93814493e-01\n",
      "            3.38390445e-01  1.23684088e-01 -1.02197167e-02  4.93070098e-02\n",
      "           -2.30300521e-01 -7.82497163e-02  2.46031057e-01  2.90246550e-01\n",
      "            6.02894009e-01 -1.65300583e-02 -1.47256915e-01 -1.14986206e-01\n",
      "           -2.27641078e-01 -1.74088519e-02]\n",
      "          [ 8.55815711e-02 -7.65680654e-03  2.45150610e-01 -5.23722441e-02\n",
      "           -7.76923258e-02 -1.29975586e-01 -3.65068177e-01 -3.50563524e-01\n",
      "           -2.63667738e-01  2.91008165e-01  2.00186283e-01  3.07451323e-01\n",
      "           -2.97891573e-01 -4.40197868e-01 -1.47593074e-01  3.93143124e-02\n",
      "            1.11510536e-01  2.34333708e-01  6.35668676e-02  3.89672578e-01\n",
      "           -4.97761423e-02 -2.04170716e-01 -3.75931833e-01 -1.98780032e-01\n",
      "            5.41392209e-02 -1.98723895e-01  2.09461987e-01  3.15806063e-01\n",
      "           -5.29855749e-01  1.93207967e-01]\n",
      "          [-5.00790678e-01  8.97779197e-02  2.73889384e-01  1.45022659e-02\n",
      "           -2.86147203e-01 -1.30906400e-01 -5.85056982e-02 -4.07511711e-02\n",
      "           -4.53691112e-02 -2.45705364e-02  4.77355916e-02 -2.70245295e-01\n",
      "           -5.41172797e-02  3.39493524e-01 -8.60093334e-02 -9.92447675e-02\n",
      "            2.41092259e-01 -5.72251062e-01  2.64164286e-01 -1.41297978e-01\n",
      "            3.66555422e-02  2.15381107e-02  2.10742275e-01 -5.98360062e-02\n",
      "           -1.51611174e-01  2.90207152e-01 -5.28645353e-01  4.54686139e-03\n",
      "           -3.01405288e-01 -1.70292983e-01]\n",
      "          [ 4.49730669e-01 -9.97184081e-03  4.36189111e-02 -3.98369554e-01\n",
      "           -1.63019345e-01  4.39515714e-02  7.93262325e-02  1.37940027e-01\n",
      "            1.92925686e-03  1.17841718e-01  1.01468718e-01 -4.09142393e-01\n",
      "            8.27473111e-03  1.71708204e-01  1.31901136e-01 -8.13613054e-02\n",
      "           -1.80143564e-01 -2.50062139e-01 -2.93045684e-02  2.53364365e-01\n",
      "           -4.36436678e-01 -1.47556275e-01 -2.54867577e-01  1.75521839e-01\n",
      "           -1.23947396e-01 -1.05237778e-01 -4.85113980e-02  9.95929616e-02\n",
      "           -8.77408476e-02 -6.81138294e-01]\n",
      "          [ 1.21488233e-01  9.81729894e-02 -4.90908663e-02 -2.42397950e-01\n",
      "            7.86604254e-02  8.47996438e-02 -1.05102545e-01 -4.84626308e-02\n",
      "           -2.07989323e-01 -3.99337347e-02 -3.46686541e-01  9.33153252e-02\n",
      "           -2.11167212e-01  5.32414832e-02 -3.14382872e-01 -1.31940906e-01\n",
      "           -2.47061822e-02 -3.71343774e-01  2.57478473e-02 -8.47799716e-02\n",
      "           -3.89602686e-01 -2.91413950e-01  1.35308960e-01  2.00252403e-01\n",
      "           -2.94956686e-02  9.05074947e-02  5.00529416e-02  7.37059399e-02\n",
      "            2.87554773e-01 -3.36975091e-01]\n",
      "          [ 1.51261221e-01 -8.54198024e-02 -5.01458211e-02 -6.75850942e-02\n",
      "           -8.38854427e-02 -2.74185799e-01  4.09958900e-02  3.73634218e-01\n",
      "           -1.25517250e-02 -3.09704984e-04 -1.53684731e-01 -2.62681076e-02\n",
      "            1.04237984e-01 -8.27887279e-02 -1.01473670e-01  9.01726952e-02\n",
      "           -2.05272103e-01  5.64599629e-02  1.83429530e-01  3.04093733e-01\n",
      "           -2.02100318e-02  3.05804035e-01  2.31301081e-01 -2.22759923e-01\n",
      "           -2.72339337e-01 -6.81919448e-02  2.30076984e-01 -1.61638664e-02\n",
      "           -1.34311119e-01  3.47092139e-01]\n",
      "          [ 6.41537929e-02 -5.18900663e-01  7.09192742e-02  1.16284620e-01\n",
      "            5.04476304e-02  1.00558682e-01 -1.50432828e-02 -2.94802275e-01\n",
      "           -8.28919333e-02 -2.11446114e-01 -2.08567212e-01 -2.82430662e-01\n",
      "            1.01179634e-01  2.18902432e-02 -1.00212820e-01 -1.45196379e-01\n",
      "           -5.23756561e-03  2.41315290e-01 -4.48156259e-01  8.42721547e-02\n",
      "           -1.22024912e-01 -4.21406209e-01 -4.35072424e-01 -2.04104596e-01\n",
      "            4.90838291e-02  8.78915407e-02 -2.09962667e-01  2.27412796e-01\n",
      "            3.18188790e-01  8.85676504e-02]\n",
      "          [-1.32241653e-01  2.51427779e-01  1.68911616e-01  1.93958200e-01\n",
      "           -1.46789742e-01 -6.33825640e-01  4.73328859e-01 -3.60203349e-01\n",
      "           -7.99798428e-03  5.32350858e-01  7.39192080e-02  2.12257963e-01\n",
      "           -3.35946089e-01 -3.97498409e-01 -1.19115968e-01  2.43899057e-01\n",
      "           -7.74237332e-02 -1.77686080e-01  4.42668320e-02  2.41928058e-01\n",
      "           -3.23098453e-01 -2.70685652e-01 -1.76351801e-01  2.44768576e-01\n",
      "            5.25076900e-02  4.76764019e-01  2.09395627e-01 -7.84752028e-03\n",
      "            2.82880002e-01  4.72921689e-02]\n",
      "          [-1.57625209e-01  1.52047000e-01 -1.55703378e-01 -6.49347673e-02\n",
      "            2.96901249e-01 -2.26472289e-02 -1.79587880e-01 -1.03829061e-01\n",
      "            2.28479329e-01 -1.23551848e-01 -8.65069544e-02 -1.14104932e-01\n",
      "            4.11269909e-02 -8.61981312e-02 -3.58181438e-01 -1.98379686e-01\n",
      "           -2.08577967e-01  2.78014668e-01  1.81719441e-01  1.31315183e-01\n",
      "           -1.13001560e-01 -1.82416536e-01 -1.13484380e-01 -2.35207546e-01\n",
      "            5.58391005e-01 -5.02069207e-01  1.26116142e-01 -2.87234634e-01\n",
      "           -2.33319134e-02 -2.20923951e-01]\n",
      "          [-2.63325848e-01 -2.54955649e-01  3.92426837e-01 -2.97371154e-02\n",
      "           -1.71216214e-01  1.24277744e-01  2.31417711e-03  1.61004444e-01\n",
      "           -4.07916190e-01  6.78878997e-02  1.72779816e-01 -3.71544681e-01\n",
      "            1.00219511e-01  3.79277722e-01 -3.32228357e-03  1.83671954e-01\n",
      "            1.49944107e-01 -1.58203085e-01  8.89211257e-03 -3.50390660e-01\n",
      "           -1.00914426e-01  5.94096367e-02  1.61690184e-01  5.50343846e-03\n",
      "            1.60993262e-01 -2.46617330e-01 -2.27402017e-02  4.31100154e-03\n",
      "            4.13581178e-01 -4.78891202e-02]\n",
      "          [-1.11583513e-01  4.77427878e-03 -2.05520017e-01  4.31010715e-02\n",
      "           -8.16288250e-02 -4.00553027e-01 -1.31003514e-02 -7.10047934e-02\n",
      "           -3.65020943e-01 -1.50116538e-02  3.33030108e-01  1.16567067e-01\n",
      "            1.36831084e-01 -2.99967783e-01  1.06637718e-01  3.31943363e-02\n",
      "            1.18298108e-01  9.45026304e-02 -3.04056201e-01 -9.25750312e-03\n",
      "           -1.69465075e-01 -1.11991442e-02 -2.00664945e-01  2.93477285e-01\n",
      "           -1.92072061e-01 -2.01009581e-01  1.66780275e-02 -2.40846677e-01\n",
      "           -9.49576018e-02 -1.85585722e-01]\n",
      "          [ 3.15547659e-01  1.75711084e-01 -1.28505747e-02 -8.74787924e-02\n",
      "            2.10395574e-01  9.06063884e-02  1.11367906e-01 -5.85676217e-03\n",
      "           -3.77499713e-01 -2.51481588e-02 -1.19068360e-01  1.44238749e-01\n",
      "            2.26254859e-01 -1.47122329e-01  1.04734119e-01  3.88154332e-01\n",
      "           -1.49305109e-01  3.76089130e-01 -1.90643992e-01  5.13395746e-03\n",
      "           -2.49223466e-03  2.57123224e-03 -1.87310499e-01 -1.32192566e-01\n",
      "           -1.49306789e-01  7.31110578e-02  7.37980964e-02  4.97736273e-01\n",
      "            3.06562452e-01 -1.14004412e-01]\n",
      "          [ 7.26430516e-02  2.22962362e-01  6.84277580e-03 -1.55723296e-02\n",
      "            1.15325076e-02  1.93928945e-01 -1.89690240e-01 -7.28219067e-02\n",
      "            1.05192049e-01  6.96416851e-02  5.35723342e-02 -8.26900540e-02\n",
      "            2.17465613e-01  4.77147439e-01  9.08772668e-02 -4.31956237e-02\n",
      "            1.68988665e-01 -1.20553726e-01 -1.67635859e-01  7.33625889e-03\n",
      "           -5.77530871e-01 -2.58031139e-01 -7.78066335e-02 -3.02626959e-01\n",
      "           -2.30906012e-01 -9.76598946e-02 -3.67378213e-01 -9.08004109e-02\n",
      "           -1.19690045e-01  5.68077713e-03]\n",
      "          [ 2.58083385e-01  3.85731588e-02  4.70961131e-03  2.22386922e-02\n",
      "            5.08465709e-02 -2.27349674e-01 -2.56645423e-02  6.90388795e-02\n",
      "           -3.06511246e-01  1.93565877e-01  2.41803041e-01 -1.41179958e-01\n",
      "           -5.39647706e-02 -1.96369329e-01  1.56386224e-01 -2.37296524e-01\n",
      "           -4.97473704e-02 -1.92060333e-01  1.13937231e-02 -4.01201861e-01\n",
      "            2.96605847e-01 -2.15692549e-01  1.33928586e-02 -4.75215971e-02\n",
      "           -1.70413988e-01 -1.98513672e-01  2.09385085e-01 -1.17536813e-01\n",
      "            6.06354998e-02 -1.79220147e-01]])\n",
      "6-(20,): variable([0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.])\n",
      "7-(10, 20): variable([[-0.12749574  0.38657105  0.06586233  0.30884038  0.11269295  0.22343806\n",
      "            0.0033204   0.56474186  0.04013313  0.1271202   0.59550454 -0.42619882\n",
      "           -0.40176265  0.30655016 -0.37097418  0.61462698 -0.13079781 -0.23636597\n",
      "            0.60808767  0.46817988]\n",
      "          [ 0.590574    0.28651648 -0.27234347  0.60401557 -0.08475011  0.25375899\n",
      "            0.29954738 -0.04901849  0.19418894  0.29162736  0.11903621 -0.34766105\n",
      "            0.0943112   0.41944004 -0.21964164 -0.0473186  -0.13760763  0.58478856\n",
      "            0.21259826  0.12885074]\n",
      "          [-0.24346883  0.17052556 -0.21324272  0.01006571 -0.20107218  0.21390698\n",
      "            0.18233403 -0.06586985  0.12522832 -0.34565642 -0.47157704  0.13894786\n",
      "            0.05270679  0.20081458  0.75361657  0.29867063 -0.28865974  0.35323157\n",
      "           -0.41612644 -0.14596587]\n",
      "          [-0.02157989  0.54180652 -0.23551216 -0.26134282 -0.03113342 -0.20981027\n",
      "            0.35627356 -0.34150432 -0.36286146 -0.13845086 -0.15749169  0.61017161\n",
      "            0.30023322  0.02768613 -0.38751673  0.26701102 -0.31629585 -0.48849951\n",
      "            0.375688    0.10022605]\n",
      "          [ 0.29120112  0.10079053  0.27095363 -0.20587237 -0.32705631  0.2155391\n",
      "           -0.25406043 -0.21805479 -0.14405202  0.0055274  -0.11194271 -0.43479776\n",
      "           -0.20353001 -0.70310183  0.19771554 -0.50661513 -0.34923668  0.01649605\n",
      "           -0.23387035  0.48794407]\n",
      "          [-0.40883726  0.0844489  -0.01242232 -0.36938358  0.16547462 -0.05424771\n",
      "            0.24406161  0.26041488  0.68407526  0.42264725 -0.11674555 -0.07569834\n",
      "            0.34774289  0.20721258  0.20242736 -0.51132638 -0.0076926  -0.23338587\n",
      "            0.08851993 -0.03103788]\n",
      "          [ 0.28782384  0.10031321  0.24865873 -0.14749467 -0.29866013 -0.1296691\n",
      "           -0.00538233  0.11989831  0.71445625 -0.01336288 -0.30229636 -0.10940904\n",
      "           -0.14660192  0.15225781 -0.48724279  0.0200052   0.04949171  0.07342209\n",
      "           -0.18888793 -0.07523746]\n",
      "          [-0.45032761 -0.15600144 -0.17166787  0.13156658 -0.36561698  0.24703653\n",
      "            0.47259751 -0.6545867   0.13479485  0.21405711 -0.20157529 -0.12562838\n",
      "           -0.04202053 -0.09416975 -0.09771848 -0.52999894  0.36439924  0.34140537\n",
      "           -0.25720837 -0.46372409]\n",
      "          [ 0.16477518 -0.18208014  0.04488953 -0.10098052  0.21868375  0.21969896\n",
      "           -0.22945404 -0.4374581  -0.50056908  0.19301891 -0.3759503  -0.1602694\n",
      "           -0.18857105 -0.01662324 -0.61230543  0.05969703  0.16566889  0.02796152\n",
      "           -0.09831084  0.03080064]\n",
      "          [ 0.12618953 -0.87677082  0.61851379  0.12335834 -0.20630971 -0.12363031\n",
      "            0.15613486 -0.03671529 -0.64215881  0.65284999 -0.03495603  0.32260694\n",
      "           -0.21884538  0.48584509  0.09054983  0.19253333 -0.33053815  0.38299777\n",
      "            0.21813965  0.41167994]])\n",
      "8-(10,): variable([0. 0. 0. 0. 0. 0. 0. 0. 0. 0.])\n",
      "9-(1, 10): variable([[-1.16514981  0.90082651  0.46566245 -1.53624368  1.48825216  1.89588916\n",
      "            1.1787796  -0.17992483 -1.07075262  1.0544517 ]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dezero import Variable, Layer\n",
    "from dezero.models import Model, MLP\n",
    "import dezero.functions as F\n",
    "import dezero.layers as L\n",
    "model = MLP((10,20,30,40,1)) #5层（4个hidden1 个out）\n",
    "# 在传入数据前模型不会初始化参数，参数全都是None\n",
    "# next(model.params())\n",
    "\n",
    "# 传入toy data\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(100,1)\n",
    "y_pred = model(x)\n",
    "print(y_pred)\n",
    "model._params #{'l0', 'l1', 'l2', 'l3', 'l4'}\n",
    "model.__dict__['l0'].W.shape # (1, 10)\n",
    "\n",
    "\n",
    "for i, w in enumerate(model.params()):\n",
    "    print(f'{i}-{w.shape}: {w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试__setattr__以及__dicit__的行为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'name1'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#%%\n",
    "class nametest:\n",
    "    def __init__(self, name='name1'):\n",
    "        self.name = name\n",
    "\n",
    "tmp = nametest()\n",
    "tmp.__dict__ # out: {'name': 'name1'}\n",
    "\n",
    "# 从上面这个例子可以看出，实例tmp的所有变量的值都会被__setattr__以{name:value}的形式存到__dict__中\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Set` 带来的`.params()`遍历取出`parameters`的随机性 \n",
    "\n",
    "- `yield from`的作用是从一个`iter`中生成另一个`iter`对象，嵌套递归，把所有可能的`parameter`逐个取出\n",
    "- 当set中有不同的数据结构时，会产生随机性:每次重启kernel都不一样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 你需要用交互模式运行下面的内容\n",
    "- 每次重新启动kernel，`yield from`遍历`iterator`的顺序都是不一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'6'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp2 = iter(set([1,3,2,4,'5','6']))\n",
    "next(tmp2)\n",
    "tmp = set([1,3,2,4,'5','6'])\n",
    "\n",
    "def fun(tmp):\n",
    "    for i in tmp:\n",
    "        print(i)\n",
    "        yield i\n",
    "\n",
    "def func(tmp):\n",
    "    for i in tmp:\n",
    "        print(i)\n",
    "        yield from fun(tmp)\n",
    "\n",
    "tmp3 = func(tmp)\n",
    "next(tmp3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 `dezero/optimizers.py` 中实现的SGD解决问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(0.8165178479901415)\n",
      "variable(0.2521950747242885)\n",
      "variable(0.2504242377295966)\n",
      "variable(0.2479233160773438)\n",
      "variable(0.24329152231523804)\n",
      "variable(0.23307035987608468)\n",
      "variable(0.2055474018926681)\n",
      "variable(0.13312454541584906)\n",
      "variable(0.0817534055439662)\n",
      "variable(0.07781429408029678)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dezero import Variable, optimizers\n",
    "import dezero.functions as F\n",
    "from dezero.models import MLP\n",
    "\n",
    "np.random.seed(0)\n",
    "x = np.random.rand(100, 1)\n",
    "y = np.sin(2*np.pi*x) + np.random.rand(100, 1)\n",
    "\n",
    "lr = 0.2\n",
    "max_iter = 1000\n",
    "hidden_size = 10\n",
    "\n",
    "model = MLP((hidden_size, 1))\n",
    "\n",
    "# optimizer = optimizers.SGD(le)\n",
    "optimizer = optimizers.MomentumSGD(lr)\n",
    "optimizer.setup(model)\n",
    "# or equivalently:\n",
    "# optimizer = optimizers.SGD(lr).setup(model)\n",
    "\n",
    "for i in range(max_iter):\n",
    "    y_pred = model(x)\n",
    "    loss = F.mean_squared_error(y, y_pred)\n",
    "    model.cleargrads()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.update()\n",
    "    if i % 100 == 0:\n",
    "        print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = next(model.params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2511148658752"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "gy must be np.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m gx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28misinstance\u001b[39m(gx, np\u001b[38;5;241m.\u001b[39mndarray)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gx, \u001b[38;5;28mfloat\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgy must be np.ndarray\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: gy must be np.ndarray"
     ]
    }
   ],
   "source": [
    "# module type (cuda or np) test\n",
    "import numpy as np\n",
    "\n",
    "gx = np.zeros((2,3))\n",
    "isinstance(gx, np.ndarray)\n",
    "assert isinstance(gx, float), 'gy must be np.ndarray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable([4 5 6])\n",
      "variable([[0 0 0]\n",
      "          [1 1 1]])\n"
     ]
    }
   ],
   "source": [
    "# test with get_item function\n",
    "import numpy as np\n",
    "from dezero import Variable\n",
    "import dezero.functions as F\n",
    "\n",
    "x = Variable(np.array([[1,2,3],[4,5,6]]))\n",
    "y = F.get_item(x, 1)\n",
    "y.backward()\n",
    "print(f'{y}\\n{x.grad}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable([[1 2 3]\n",
      "          [1 2 3]\n",
      "          [4 5 6]])\n"
     ]
    }
   ],
   "source": [
    "# 多次提取同一组元素\n",
    "x = Variable(np.array([[1, 2, 3], [4, 5, 6]]))\n",
    "indices = np.array([0, 0, 1])\n",
    "y = F.get_item(x, indices)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable([4 5 6])\n",
      "variable([3 6])\n"
     ]
    }
   ],
   "source": [
    "# 重写Variable类中的__getitem__特殊方法，让get_item函数也可以在Variable类型上使用\n",
    "# 或者直接在dezero.core.py中改写setup_variable\n",
    "Variable.__getitem__ = F.get_item\n",
    "\n",
    "# 行为和np.ndarray的切片一致\n",
    "y = x[1]\n",
    "print(y)\n",
    "y = x[:,2]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dezero import Variable, as_variable\n",
    "import dezero.functions as F\n",
    "from dezero.models import MLP\n",
    "def softmaxld(x):\n",
    "    # x = as_variable(x)\n",
    "    y = F.exp(x)\n",
    "    sum_y = F.sum(y)\n",
    "    return y/sum_y\n",
    "\n",
    "model = MLP((10, 3)) # 2 layer fc layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable([[-0.05369075  0.74685377 -0.00334219]])\n"
     ]
    }
   ],
   "source": [
    "# x = Variable(np.array([[0.2, -0.4]]))\n",
    "x = np.array([[0.2, -0.4]])\n",
    "y = model(x)\n",
    "p = softmaxld(y)\n",
    "\n",
    "print(y)\n",
    "# print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable([[-7.89139711e-17 -1.75721930e-16 -8.29888980e-17]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.backward(retain_grad=True)\n",
    "y.grad # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(1.4967442462341742)\n"
     ]
    }
   ],
   "source": [
    "# 测试softmax与cross_entropy_loss\n",
    "from dezero import Variable, as_variable\n",
    "import dezero.functions as F\n",
    "from dezero.models import MLP\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "model = MLP((10, 3))\n",
    "x = np.array([[0.2, -0.4], [0.3, 0.5], [1.3, -3.2], [2.1, 0.3]])\n",
    "\n",
    "t = np.array([2, 0, 1, 0])\n",
    "y = model(x)\n",
    "loss = F.softmax_cross_entropy(y, t)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试 Max()定义中的反向传播掩码cond的shape\n",
    "x = Variable(np.random.rand(10,3))\n",
    "y = x.max(axis = 1, keepdims = True)\n",
    "y.shape # shape (10, 1)\n",
    "cond = (x.data == y.data)\n",
    "cond.shape #shape (10, 1) be broadcast to shape (10, 3)\n",
    "cond.ravel().shape\n",
    "\n",
    "x2 = np.random.rand(10,1)\n",
    "x2.shape # (10, 1)\n",
    "x2.ravel().shape #(10, 0)\n",
    "t.ravel().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 螺旋数据集 （step 48）\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dezero loaded from: ['d:\\\\GITrepo\\\\LLM-from-scratch\\\\dezero']\n",
      "train_set shape: (300, 2), label shape: (300,)\n",
      "data example: (array([-0.06990694, -0.00360829], dtype=float32), np.int32(1))\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import dezero\n",
    "print(f'dezero loaded from: {dezero.__path__}')\n",
    "from dezero import optimizers\n",
    "import dezero.functions as F\n",
    "from dezero.models import MLP\n",
    "\n",
    "max_epoch = 100\n",
    "print_every = 10\n",
    "\n",
    "batch_size = 30\n",
    "hidden_size = 10\n",
    "\n",
    "assert print_every >=1 , 'print_every must larger than 1'\n",
    "lr = 1.0\n",
    "\n",
    "# load data\n",
    "# first transform data\n",
    "def f(x):\n",
    "    y = x / 2.0\n",
    "    return y\n",
    "\n",
    "train_set = dezero.datasets.Spiral(transform = f)\n",
    "\n",
    "print(f'train_set shape: {train_set.data.shape}, label shape: {train_set.label.shape}')\n",
    "print(f'data example: {train_set[0]}')\n",
    "\n",
    "# 2 layer fc nn, 3 classes\n",
    "model = MLP((hidden_size, 3))\n",
    "optimizer = optimizers.SGD(lr).setup(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, epoch_avg_loss: 0.79\n",
      "epoch: 20, epoch_avg_loss: 0.74\n",
      "epoch: 30, epoch_avg_loss: 0.73\n",
      "epoch: 40, epoch_avg_loss: 0.72\n",
      "epoch: 50, epoch_avg_loss: 0.69\n",
      "epoch: 60, epoch_avg_loss: 0.63\n",
      "epoch: 70, epoch_avg_loss: 0.57\n",
      "epoch: 80, epoch_avg_loss: 0.49\n",
      "epoch: 90, epoch_avg_loss: 0.40\n",
      "epoch: 100, epoch_avg_loss: 0.34\n"
     ]
    }
   ],
   "source": [
    "data_size = len(train_set)\n",
    "max_iter = math.ceil(data_size / batch_size)\n",
    "np.random.seed(0)\n",
    "for epoch in range(max_epoch):\n",
    "\n",
    "    # 随机打乱所有index\n",
    "    \n",
    "    index = np.random.permutation(data_size)\n",
    "    sum_loss = 0\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        # 等距切分打乱后的index\n",
    "        batch_index = index[i*batch_size : (i+1)*batch_size]\n",
    "\n",
    "        # 小批量地读入数据用于训练，防止内存被冲爆\n",
    "        batch = [train_set[i] for i in batch_index]\n",
    "        batch_x = np.array([example[0] for example in batch])\n",
    "        batch_t = np.array([example[1] for example in batch])\n",
    "\n",
    "        y = model(batch_x)\n",
    "        loss = F.softmax_cross_entropy(y, batch_t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "\n",
    "        # 求所有数据的loss总和，并非batch loss\n",
    "        sum_loss += float(loss.data) * len(batch_t)\n",
    "\n",
    "    avg_loss = sum_loss / data_size\n",
    "    if epoch % print_every == print_every-1 :\n",
    "        print(f'epoch: {epoch+1}, epoch_avg_loss: {avg_loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.13981389, -0.00721657], dtype=float32), np.int32(1))\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# 测试 Datasets 类\n",
    "import dezero\n",
    "\n",
    "train_set = dezero.datasets.Spiral(train = True)\n",
    "print(train_set[0])\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2) (10,)\n",
      "(10, 2) (10,)\n"
     ]
    }
   ],
   "source": [
    "# dataloader class test\n",
    "from dezero.datasets import Spiral\n",
    "from dezero import DataLoader\n",
    "\n",
    "batch_size = 10\n",
    "max_epoch = 1\n",
    "\n",
    "train_set = Spiral(train = True)\n",
    "test_set = Spiral(train = False)\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size, shuffle = False)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for x, t in train_loader:\n",
    "        print(x.shape, t.shape)\n",
    "        # break: 截断输出，只输出1个用作展示\n",
    "        break\n",
    "    for x, t in test_loader:\n",
    "        print(x.shape, t.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable(0.6666666666666666)\n"
     ]
    }
   ],
   "source": [
    "# test with accuracy\n",
    "import numpy as np\n",
    "import dezero.functions as F\n",
    "\n",
    "y = np.array([[0.2, 0.8, 0. ], [0.1, 0.9, 0], [0.8, 0.1, 0.1]])\n",
    "t = np.array([1, 2, 0])\n",
    "acc = F.accuracy(y, t)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dezero loaded from: ['d:\\\\GITrepo\\\\LLM-from-scratch\\\\dezero']\n",
      "train_set shape: (300, 2), label shape: (300,)\n",
      "data example: (array([-0.13981389, -0.00721657], dtype=float32), np.int32(1))\n"
     ]
    }
   ],
   "source": [
    "# use Spiral data to train a MLP\n",
    "import math\n",
    "import numpy as np\n",
    "import dezero\n",
    "import dezero.datasets\n",
    "print(f'dezero loaded from: {dezero.__path__}')\n",
    "from dezero import optimizers\n",
    "import dezero.functions as F\n",
    "from dezero.models import MLP\n",
    "\n",
    "max_epoch = 300\n",
    "print_every = 10\n",
    "\n",
    "batch_size = 30\n",
    "hidden_size = 10\n",
    "\n",
    "assert print_every >=1 , 'print_every must larger than 1'\n",
    "lr = 1.0\n",
    "\n",
    "# load data\n",
    "train_set = dezero.datasets.Spiral(train = True)\n",
    "test_set = dezero.datasets.Spiral(train = False)\n",
    "train_loader = dezero.DataLoader(train_set, batch_size)\n",
    "test_loader = dezero.DataLoader(test_set, batch_size, shuffle = False)\n",
    "\n",
    "print(f'train_set shape: {train_set.data.shape}, label shape: {train_set.label.shape}')\n",
    "print(f'data example: {train_set[0]}')\n",
    "\n",
    "# 2 layer fc nn, 3 classes\n",
    "model = MLP((hidden_size, 3))\n",
    "optimizer = optimizers.SGD(lr).setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, train_avg_loss: 0.27, test_avg_acc: 0.93\n",
      "test_avg_loss: 0.01, test_avg_acc: 0.89\n",
      "epoch: 20, train_avg_loss: 0.24, test_avg_acc: 0.92\n",
      "test_avg_loss: 0.01, test_avg_acc: 0.92\n",
      "epoch: 30, train_avg_loss: 0.21, test_avg_acc: 0.92\n",
      "test_avg_loss: 0.01, test_avg_acc: 0.90\n",
      "epoch: 40, train_avg_loss: 0.20, test_avg_acc: 0.93\n",
      "test_avg_loss: 0.01, test_avg_acc: 0.92\n",
      "epoch: 50, train_avg_loss: 0.19, test_avg_acc: 0.92\n",
      "test_avg_loss: 0.01, test_avg_acc: 0.91\n",
      "epoch: 60, train_avg_loss: 0.17, test_avg_acc: 0.94\n",
      "test_avg_loss: 0.01, test_avg_acc: 0.93\n",
      "epoch: 70, train_avg_loss: 0.17, test_avg_acc: 0.94\n",
      "test_avg_loss: 0.01, test_avg_acc: 0.93\n",
      "epoch: 80, train_avg_loss: 0.15, test_avg_acc: 0.95\n",
      "test_avg_loss: 0.01, test_avg_acc: 0.94\n",
      "epoch: 90, train_avg_loss: 0.15, test_avg_acc: 0.95\n",
      "test_avg_loss: 0.01, test_avg_acc: 0.93\n",
      "epoch: 100, train_avg_loss: 0.14, test_avg_acc: 0.95\n",
      "test_avg_loss: 0.01, test_avg_acc: 0.94\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "data_size = len(train_set)\n",
    "max_iter = math.ceil(data_size / batch_size)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "\n",
    "    for x, t in train_loader:\n",
    "        y = model(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        acc = F.accuracy(y, t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "\n",
    "        sum_loss += float(loss.data) * len(t)\n",
    "        sum_acc += float(acc.data) * len(t)\n",
    "\n",
    "    # print training info\n",
    "    avg_loss = sum_loss / data_size\n",
    "    avg_acc = sum_acc / data_size\n",
    "    if epoch % print_every == print_every-1 :\n",
    "        print(f'epoch: {epoch+1}, train_avg_loss: {avg_loss:.2f}, test_avg_acc: {avg_acc:.2f}')\n",
    "\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "    # print eval info\n",
    "    with dezero.no_grad():\n",
    "        for x, t in test_loader:\n",
    "            y = model(x)\n",
    "            loss = F.softmax_cross_entropy(y, t)\n",
    "            acc = F.accuracy(y, t)\n",
    "            sum_loss += float(loss.data)\n",
    "            sum_acc += float(acc.data) * len(t)\n",
    "    \n",
    "    # print eval(test) info\n",
    "    avg_loss = sum_loss / data_size\n",
    "    avg_acc = sum_acc / data_size\n",
    "    if epoch % print_every == print_every-1 :\n",
    "        print(f'test_avg_loss: {avg_loss:.2f}, test_avg_acc: {avg_acc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "import dezero\n",
    "train_set = dezero.datasets.MNIST(train = True, transform = None)\n",
    "test_set = dezero.datasets.MNIST(train = False, transform = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "<class 'numpy.ndarray'> (1, 28, 28)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x, t = train_set[0]\n",
    "print(type(x), x.shape)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x.reshape(28, 28), cmap = 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dezero loaded from: ['d:\\\\GITrepo\\\\LLM-from-scratch\\\\dezero']\n"
     ]
    }
   ],
   "source": [
    "# start training a NN\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import dezero\n",
    "import dezero.datasets\n",
    "print(f'dezero loaded from: {dezero.__path__}')\n",
    "from dezero import optimizers\n",
    "import dezero.functions as F\n",
    "from dezero.models import MLP\n",
    "# def transform function to preprocess\n",
    "\n",
    "def f(x):\n",
    "    x = x.flatten()\n",
    "    x = x.astype(np.float32)\n",
    "    x /= 255.0\n",
    "    return x\n",
    "\n",
    "# setup hyper-params\n",
    "\n",
    "max_epoch = 5\n",
    "print_every = 1\n",
    "\n",
    "batch_size = 100\n",
    "hidden_size = 1000\n",
    "lr = 1.0\n",
    "\n",
    "train_set = dezero.datasets.MNIST(train = True, transform = f)\n",
    "test_set = dezero.datasets.MNIST(train=False, transform = f)\n",
    "train_loader = dezero.DataLoader(train_set, batch_size)\n",
    "test_loader = dezero.DataLoader(test_set, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, train_avg_loss: 0.4034, train_avg_acc: 0.8903\n",
      "test_avg_loss: 0.2049, test_avg_acc: 0.9417\n",
      "epoch: 2, train_avg_loss: 0.1753, train_avg_acc: 0.9500\n",
      "test_avg_loss: 0.1400, test_avg_acc: 0.9589\n",
      "epoch: 3, train_avg_loss: 0.1223, train_avg_acc: 0.9646\n",
      "test_avg_loss: 0.1231, test_avg_acc: 0.9606\n",
      "epoch: 4, train_avg_loss: 0.0930, train_avg_acc: 0.9737\n",
      "test_avg_loss: 0.0898, test_avg_acc: 0.9729\n",
      "epoch: 5, train_avg_loss: 0.0742, train_avg_acc: 0.9785\n",
      "test_avg_loss: 0.0864, test_avg_acc: 0.9717\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "assert print_every >=1 , 'print_every must larger than 1'\n",
    "\n",
    "model = MLP((hidden_size, hidden_size, 10), activation=F.relu)\n",
    "optimizer = optimizers.MomentumSGD().setup(model)\n",
    "\n",
    "# max_iter = math.ceil(data_size / batch_size)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "\n",
    "    for x, t in train_loader:\n",
    "        y = model(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        acc = F.accuracy(y, t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "\n",
    "        sum_loss += float(loss.data) * len(t)\n",
    "        sum_acc += float(acc.data) * len(t)\n",
    "\n",
    "    # print training info\n",
    "    avg_loss = sum_loss / len(train_set)\n",
    "    avg_acc = sum_acc / len(train_set)\n",
    "    if epoch % print_every == print_every-1 :\n",
    "        print(f'epoch: {epoch+1}, train_avg_loss: {avg_loss:.4f}, train_avg_acc: {avg_acc:.4f}')\n",
    "\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "    # print eval info\n",
    "    with dezero.no_grad():\n",
    "        for x, t in test_loader:\n",
    "            y = model(x)\n",
    "            loss = F.softmax_cross_entropy(y, t)\n",
    "            acc = F.accuracy(y, t)\n",
    "            sum_loss += float(loss.data) * len(t)\n",
    "            sum_acc += float(acc.data) * len(t)\n",
    "    \n",
    "    # print eval(test) info\n",
    "    avg_loss = sum_loss / len(test_set)\n",
    "    avg_acc = sum_acc / len(test_set)\n",
    "    if epoch % print_every == print_every-1 :\n",
    "        print(f'test_avg_loss: {avg_loss:.4f}, test_avg_acc: {avg_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-HW-Py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
